D09-1119	P05-1045	p	As discussed above, all state-of-the-art published methods rely on lexical features for such tasks (Zhang et al., 2001; Sha and Pereira, 2003; Finkel et al., 2005; Ratinov and Roth, 2009).
W97-0322	P95-1026	p	"While (Yarowsky, 1995) does not discuss distinguishing more than 2 senses of a word, there is no immediate reason to doubt that the ""one sense per collocation"" rule (Yarowsky, 1993) would still hold for a larger number of senses."
W96-0410	P85-1008	o	First, as originally advocated by Hobbs (1985), we adopt an ONTOLOGICALLY PROMISCUOUS representation that includes a wide variety of types of entities.
W06-1618	W96-0213	o	Part-of-speech tags are assigned by the MXPOST maximum-entropy based part-of-speech tagger (Ratnaparkhi, 1996).
C08-1082	J05-4002	o	Many 649 similarity measures and weighting functions have been proposed for distributional vectors; comparative studies include Lee (1999), Curran (2003) and Weeds and Weir (2005).
P03-1003	J93-2003	o	To help our model learn that it is desirable to copy answer words into the question, we add to each corpus a list of identical dictionary word pairs w iw i . For each corpus, we use GIZA (Al-Onaizan et al. , 1999), a publicly available SMT package that implements the IBM models (Brown et al. , 1993), to train a QA noisy-channel model that maps flattened answer parse trees, obtained using the cut procedure described in Section 3.1, into questions.
D08-1076	P03-1021	o	A class of training criteria that provides a tighter connection between the decision rule and the final error metric is known as Minimum Error Rate Training (MERT) and has been suggested for SMT in (Och, 2003).
N06-1054	P05-1045	o	should appear with at most one value in each announcement, although the field and value may be repeated (Finkel et al. , 2005).
P04-1043	P97-1003	o	The sentences were processed using Collins parser (Collins, 1997) to generate parse-trees automatically.
C08-1017	N03-1017	o	However, Moores Law, the driving force of change in computing since then, has opened the way for recent progress in the field, such as Statistical Machine Translation (SMT) (Koehn et al. 2003).
E99-1028	P95-1026	o	"213 Proceedings of EACL '99 Table 2: The result of disambiguation experiment(two senses) (6) \[__ 122 ""-~cause~ e~'ect ~ require a-~ ""-Telose, open, ~ rrect(~ ""-'(fall, decline, win} \] 278 ""-~feel, think, sense T T 280 {hit, attack, strike} I 250 {leave, remain, go} \[ 183 gcty t ~Ol accomplish, operate'}-216 --{occur, happen, ~ --{order, request, arrange-'~""~ 240 ""-~ass, adopt, ~ 274 -'~roduce, create, gro'~~""--""""2~ --~ush, attack, pull~ -~s~ve, 223 ""-{ship, put, send} {stop, end, move} {add, append, total} {keep, maintain, protect} Total 215(77.3 181(72.4 160(87.4 349(92.3) ~-~ Correct(%)\] 83(77.0) 113(86.2) I 169(87.5) J Yarowsky used an unsupervised learning procedure to perform noun WSD (Yarowsky, 1995)."
D07-1027	P04-1041	o	4.2 Adaptation to Chinese (Cahill et al. , 2004)s algorithm (Section 3.2) only resolves certain NLDs with known types of antecedents (TOPIC, TOPIC REL and FOCUS) at fstructures.
C08-1005	P03-1021	o	imum error rate training (MERT) (Och, 2003) to maximize BLEU score (Papineni et al., 2002).
I08-1024	J93-2003	o	These probabilities are estimated with IBM model 1 (Brown et al., 1993) on parallel corpora.
W03-1014	P02-1053	o	For example, (Spertus, 1997) developed a system to identify inflammatory texts and (Turney, 2002; Pang et al. , 2002) developed methods for classifying reviews as positive or negative.
N04-1005	W95-0107	o	These tags are drawn from a tagset which is constructed by extending each argument label by three additional symbols a11 a24 a35 a24a4a12, following (Ramshaw and Marcus, 1995).
N06-1031	J93-2004	o	The yield of this tree gives the target translation: the gunman was killed by police . The Penn English Treebank (PTB) (Marcus et al. , 1993) is our source of syntactic information, largely due to the availability of reliable parsers.
P04-3019	J93-1003	o	Smadja (1993) also detailed techniques for collocation extraction and developed a program called XTRACT, which is capable of computing flexible collocations based on elaborated statistical calculation.
N09-1049	C08-1064	o	Lopez (2008) explores whether lexical reordering or the phrase discontiguity inherent in hierarchical rules explains improvements over phrase-based systems.
J07-4004	P04-1041	o	Statistical parsers have been developed for TAG (Chiang 2000; Sarkar and Joshi 2003), LFG (Riezler et al. 2002; Kaplan et al. 2004; Cahill et al. 2004), and HPSG (Toutanova et al. 2002; Toutanova, Markova, and Manning 2004; Miyao and Tsujii 2004; Malouf and van Noord 2004), among others.
W95-0101	J93-2004	o	(Francis and Kucera, 1982; Marcus et al. , 1993), training on a corpus of one type and then applying the tagger to a corpus of a different type usually results in a tagger with low accuracy \[Weischedel et al. , 1993\].
A94-1006	J93-2003	o	3 Bilingual Task: An Application for Word Alignment 3.1 Sentence and word alignment Bilingual alignment methods (Warwick et al. , 1990; Brown et al. , 1991a; Brown et al. , 1993; Gale and Church, 1991b; Gale and Church, 1991a; Kay and Roscheisen, 1993; Simard et al. , 1992; Church, 1993; Kupiec, 1993a; Matsumoto et al. , 1993; Dagan et al. , 1993).
W06-1615	W96-0213	p	Discriminative taggers and chunkers have been the state-of-the-art for more than a decade (Ratnaparkhi, 1996; Sha and Pereira, 2003).
W06-1638	J93-2004	o	We used sections 220 of the Penn Treebank 2 Wall Street Journal corpus (Marcus et al. , 1993) for training, section 22 as development set and section 23 for testing.
W03-1702	J93-1003	o	To make sense tagging more precise, it is advisable to place constraint on the translation counterpart c of w. SWAT considers only those translations c that has been linked with w based the Competitive Linking Algorithm (Melamed 1997) and logarithmic likelihood ratio (Dunning 1993).
W99-0305	J96-2004	o	However, CHECK moves are almost always about some information which the speaker has been told \[Carletta et al.1996\] -a description that models the backward looking functionality of a dialogue act.
D07-1003	W96-0213	o	We tokenized sentences using the standard treebank tokenization script, and then we performed part-of-speech tagging using MXPOST tagger (Ratnaparkhi, 1996).
E09-3005	W06-1615	o	Intuitively, if we are able to find good correspondences among features, then the augmented labeled source domain data should transfer better to a target domain (where no labeled data is available) (Blitzer et al., 2006).
P09-1051	P06-1101	o	An extension to WordNet was presented by (Snow et al., 2006).
D09-1107	N03-1017	o	While theoretically sound, this approach is computationally challenging both in practice (DeNero et al., 2008) and in theory (DeNero and Klein, 2008), may suffer from reference reachability problems (DeNero et al., 2006), and in the end may lead to inferior translation quality (Koehn et al., 2003).
P06-1141	P05-1045	n	We also compare our performance against (Bunescu and Mooney, 2004) and (Finkel et al. , 2005) and find that we manage higher relative improvement than existing work despite starting from a very competitive baseline CRF.
C00-1039	J96-2004	o	It ewduato.s the pairwise agreement mnong a set; of coders making category.iudgment, correcting tbr expected chance agreement (Carletta, 1996).
D09-1038	N06-1033	n	Although this method is comparatively easy to be implemented, it just achieves the same performance as the synchronous binarization method (Zhang et al., 2006) for syntaxbased SMT systems.
P05-1018	P97-1003	p	We employ a robust statistical parser (Collins, 1997) to determine the constituent structure for each sentence, from which subjects (s), objects (o), and relations other than subject or object (x) are identified.
J05-1003	W02-1001	o	The boosting approach to ranking has been applied to named entity segmentation (Collins 2002a) and natural language generation (Walker, Rambow, and Rogati 2001).
J07-1003	N03-1017	p	Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005).
P09-1029	W02-1011	o	Specifically, we explore the statistical term weighting features of the word generation model with Support Vector machine (SVM), faithfully reproducing previous work as closely as possible (Pang et al., 2002).
P07-1039	J93-2003	o	They can be seen as extensions of the simpler IBM models 1 and 2 (Brown et al. , 1993).
W98-1109	J92-4003	o	While Schiitze and Pedersen (1993), Brown et al (1992) and Futrelle and Gauch (1993) all demonstrate the ability of their systems to identify word similarity using clustering on the most frequently occurring words in their corpus, only Grefenstette (1992) demonstrates his system by generating word similarities with respect to a set of target words.
D07-1049	P07-1065	o	Wehope the present work will, together with Talbot and Osborne (2007), establish the Bloom filter as a practical alternative to conventional associative data structures used in computational linguistics.
N09-2006	P03-1021	o	Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate (MER) (Och, 2003) training, proposes directions to search for a better weight-vector  to combine feature functions.
W09-0412	J93-2003	o	We then built separate English-to-Spanish and Spanish-to-English directed word alignments using IBM model 4 (Brown et al., 1993), combined them using the intersect+grow heuristic (Och and Ney, 2003), and extracted phrase-level translation pairs of maximum length 7 using the alignment template approach (Och and Ney, 2004).
N07-1008	P06-1091	o	In (Tillmann and Zhang, 2006) the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU.
D07-1117	W96-0213	p	Hidden Markov models are simple and effective, but unlike discriminative models, such as Maximum Entropy models (Ratnaparkhi, 1996) and Conditional Random Fields (John Lafferty, 2001), they have more difficulty utilizing a rich set of conditionally dependent features.
J07-3004	P04-1041	o	Because treebank annotation for individual formalisms is prohibitively expensive, there have been a number of efforts to extract TAGs, LFGs, and, more recently, HPSGs, from the Penn Treebank (Xia 1999; Chen and Vijay-Shanker 2000; Xia, Palmer, and Joshi 2000; Xia 2001; Cahill et al. 2002; Miyao, Ninomiya, and Tsujii 2004; ODonovan et al. 2005; Shen and Joshi 2005; Chen, Bangalore, and Vijay-Shanker 2006).
P09-1064	D07-1014	p	Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007).
D07-1033	P04-1015	o	With regard to the local update, (B), in Algorithm 4.2, early updates (Collins and Roark, 2004) and y-good requirement in (Daume III and Marcu, 2005) resemble our local update in that they tried to avoid the situation where the correct answer cannot be output.
P04-1052	J93-2004	o	Also, attribute classi cation is a hard problem and there is no existing classi cation scheme that can be used for open domains like newswire; for example, WordNet (Miller et al. , 1993) organises adjectives as concepts that are related by the non-hierarchical relations of synonymy and antonymy (unlike nouns that are related through hierarchical links such as hyponymy, hypernymy and metonymy).
J03-4003	P97-1003	o	(Johnson [1997] notes that this structure has a higher probability than the correct, flat structure, given counts taken from the treebank for a standard PCFG).
N04-2003	W96-0213	p	Maximum Entropy (MaxEnt) principle has been successfully applied in many classification and tagging tasks (Ratnaparkhi, 1996; K. Nigam and A.McCallum, 1999; A. McCallum and Pereira, 2000).
W09-0809	N03-1017	o	We are also interested in examining the approach within a standard phrase-based decoder such as Moses (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005).
P07-1091	N03-1017	o	For example, the distancebased reordering model (Koehn et al. , 2003) allows a decoder to translate in non-monotonous order, under the constraint that the distance between two phrases translated consecutively does not exceed a limit known as distortion limit.
L08-1616	W02-1011	o	(HICSS-35</booktitle> <contexts> <context>documents, genres also work on an intra-document, or page segment level because a single document can contain instances of multiple genres, e.g., contact information, list of publications, C.V., see (Rehm, 2002; Rehm, 2007; Mehler et al., 2007).
J98-1004	J92-4003	o	This set of context vectors is then clustered into a predetermined number of coherent clusters or context groups using Buckshot (Cutting et al. 1992), a combination of the EM algorithm and agglomerative clustering.
P04-1064	J93-2003	n	Although the first three are particular cases where N=1 and/or M=1, the distinction is relevant, because most word-based translation models (eg IBM models (Brown et al. , 1993)) can typically not accommodate general M-N alignments.
P06-2034	W02-1001	o	For a full description of the algorithm, see (Collins, 2002a).
W05-0836	P03-1021	o	2.1 Minimum Error Rate Training The predominant approach to reconciling the mismatch between the MAP decision rule and the evaluation metric has been to train the parameters  of the exponential model to correlate the MAP choice with the maximum score as indicated by the evaluation metric on a development set with known references (Och, 2003).
N07-2007	N03-1017	o	The baseline we measure against in all of these experiments is the state-of-the-art grow-diag-final (gdf ) alignment refinement heuristic commonly used in phrase-based SMT (Koehn et al. , 2003).
J08-3003	P97-1003	o	The results so far mainly come from studies where a parser originally developed for English,such as the Collins parser (Collins 1997,1999), is applied to a new language,which often leads to a signicant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004).
C04-1194	J90-1003	o	As (Church and Hanks, 1990), we adopted an evaluation of mutual information as a cohesion measure of each cooccurrence.
W00-0508	J93-2003	o	The sequence Ws is thought as a noisy version of WT and the best guess I)d~ is then computed as ^ W~ = argmax P(WTWs) wT = argmax P(WslWT)P(WT) (1) wT In (Brown et al. , 1993) they propose a method for maximizing P(WTIWs) by estimating P(WT) and P(WsIWT) and solving the problem in equation 1.
W07-2216	W02-1001	o	These include the perceptron (Collins, 2002) and its large-margin variants (Crammer and Singer, 2003; McDonald et al. , 2005a).
I05-4002	J93-2004	o	For many languages, large-scale syntactically annotated corpora have been built (e.g. the Penn Treebank (Marcus et al. , 1993)), and many parsing algorithms using CFGs have been proposed.
N06-2029	P02-1040	o	For evaluation, we used the BLEU metrics, which calculates the geometric mean of n-gram precision for the MT outputs found in reference translations (Papineni et al. , 2002).
P93-1022	J90-1003	o	The mutual information of a cooccurrence pair, which measures the degree of association between the two words (Church and Hanks, 1990), is defined as (Fano, 1961): P(xly) I(x,y) -log 2 P(x,y) _ log 2 (1) P(x)P(y) P(x) = log 2 P(y\[x) P(Y) where P(x) and P(y) are the probabilities of the events x and y (occurrences of words, in our case) and P(x, y) is the probability of the joint event (a cooccurrence pair).
I08-2097	D07-1013	o	sentence length: The longer the sentence is, the poorer the parser performs (McDonald and Nivre, 2007).
I08-1030	P03-1021	o	2 Phrase-based statistical machine translation Phrase-based SMT uses a framework of log-linear models (Och, 2003) to integrate multiple features.
P99-1067	J93-1003	p	They were based on mutual information (Church & Hanks, 1989), conditional probabilities (Rapp, 1996), or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio (Dunning, 1993).
N07-1007	P03-1021	o	(2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004).
E06-1004	J93-2003	o	Exact Decoding is the original decoding problem as defined in (Brown et al. , 1993) and Relaxed Decoding is the relaxation of the decoding problem typically used in practice.
D09-1050	J97-3002	o	Since many concepts are expressed by idiomatic multiword expressions instead of single words, and different languages may realize the same concept using different numbers of words (Ma et al., 2007; Wu, 1997), word alignment based methods, which are highly dependent on the probability information at the lexical level, are not well suited for this type of translation.
W02-0906	J93-1003	o	Method Number of frames Number of verbs Linguistic resources F-Score (evaluation based on a gold standard) Coverage on a corpus C. Manning (1993) 19 200 POS tagger + simple finite state parser 58 T. Briscoe & J. Carroll (1997) 161 14 Full parser 55 A. Sarkar & D. Zeman (2000) 137 914 Annotated treebank 88 D. Kawahara et al.
P09-1064	P02-1040	o	1 Introduction In statistical machine translation, output translations are evaluated by their similarity to human reference translations, where similarity is most often measured by BLEU (Papineni et al., 2002).
D09-1084	C98-2122	o	Method Correlation Edge-counting 0.664 Jiang & Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al.
P05-1033	J93-2003	o	The basic phrase-based model is an instance of the noisy-channel approach (Brown et al. , 1993),1 in which the translation of a French sentence f into an 1Throughout this paper, we follow the convention of Brown et al. of designating the source and target languages as French and English, respectively.
C08-1122	W03-1805	o	Tomokiyo and Hurst (2003) use pointwise KLdivergence between multiple language models for scoring both phraseness and informativeness of phrases.
C08-1127	D07-1091	o	2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few.
J06-4003	J93-1003	o	For English, we have used sections 03-06 of the WSJ portion of the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993) distributed by the Linguistic Data Consortium (LDC), which have frequently been used to evaluate sentence boundary detection systems before; compare Section 7.
I05-2012	J93-2003	o	In this paper, we propose an alignment algorithm between English and Korean conceptual units (or between English and Korean term constituents) in English-Korean technical term pairs based on IBM Model (Brown et al. , 1993).
W08-0804	P07-1056	p	3 Experiments We evaluated the effect of random feature mixing on four popular learning methods: Perceptron, MIRA (Crammer et al., 2006), SVM and Maximum entropy; with 4 NLP datasets: 20 Newsgroups1, Reuters (Lewis et al., 2004), Sentiment (Blitzer et al., 2007) and Spam (Bickel, 2006).
J05-3003	P97-1003	o	Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees: Head/argument/modifier distinctions are made for each node in the tree based on Magerman (1994) and Collins (1997); 336 ODonovan et al. Large-Scale Induction and Evaluation of Lexical Resources the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the treebank, and finally an HPSG category is assigned to each node in the tree in accordance with its CFG category.
D09-1135	P05-1010	o	Then, some manual and automatic symbol splitting methods are presented, which get comparable performance with lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005).
D07-1070	W06-1615	o	However, another approach is to train a separate out-of-domain parser, and use this to generate additional features on the supervised and unsupervised in-domain data (Blitzer et al. , 2006).
C08-1135	P02-1053	o	Another possible comparison could be with a version of Turney's (2002) sentiment classification method applied to Chinese.
D08-1011	P07-1040	p	2 Confusion-network-based MT system combination The current state-of-the-art is confusion-networkbased MT system combination as described by 98  Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b).
H05-1095	P03-1021	o	Instead, and as suggested by Och (2003), we chose to maximize directly the quality of the translations produced by the system, as measured with a machine translation evaluation metric.
P06-1067	J93-2003	o	N-gram language models have also been used in Statistical Machine Translation (SMT) as proposed by (Brown et al. , 1990; Brown et al. , 1993).
P09-1027	P07-1056	o	We will employ the structural correspondence learning (SCL) domain adaption algorithm used in (Blitzer et al., 2007) for linking the translated text and the natural text.
E09-1082	N03-1003	o	(2006) propose using a statistical word alignment algorithm as a more robust way of aligning (monolingual) outputs into a confusion network for system com2Barzilay and Lee (2003) construct lattices over paraphrases using an iterative pairwise multiple sequence alignment (MSA) algorithm.
N03-1028	W02-1001	o	Minor variants support voted perceptron (Collins, 2002) and MEMMs (McCallum et al. , 2000) with the same ef cient feature encoding.
P03-1055	W96-0213	o	Templates for local features are similar to the ones employed by Ratnaparkhi (1996) for POS-tagging (Table 3), though as our input already includes POStags, we can make use of part-of-speech information as well.
W03-0427	P95-1026	o	Not unlike (Yarowsky, 1995) we use confidence of our classifier on unannotated data to enrich itself; that is, by adding confidently-classified instances to the memory.
E06-1031	W05-0909	o	Examples of such methods are the introduction of information weights as in the NIST measure or the comparison of stems or synonyms, as in METEOR (Banerjee and Lavie, 2005).
D07-1083	P06-1028	o	(Suzuki et al. , 2006) 88.02 (+0.82) + unlabeled data (17M  27M words) 88.41 (+0.39) + supplied gazetters 88.90 (+0.49) + add dev.
D09-1147	P07-1019	o	3.1 Translation Model Form We first assume the general hypergraph setting of Huang and Chiang (2007), namely, that derivations under our translation model form a hypergraph.
P05-2001	W96-0213	o	It will also be relevant to apply advanced statistical models that can incorporate various useful information to this task, e.g., the maximum entropy model (Ratnaparkhi, 1996).
W03-0416	J92-4003	o	The idea of word class (Brown et al. , 1992) gives a general solution to this problem.
W06-1608	J93-2004	o	The parser is trained on dependencies extracted from the English Penn Treebank version 3.0 (Marcus et al. , 1993) by using the head-percolation rules of (Yamada and Matsumoto, 2003).
W07-2206	W96-0213	o	The supertagger uses a log-linear model to define a distribution over the lexical category set for each word and the previous two categories (Ratnaparkhi, 1996) and the forward backward algorithm efficiently sums over all histories to give a distribution for each word.
I08-2119	N07-1015	o	Early work employed a diverse range of features in a linear classifier (commonly referred to as feature-based approaches), including lexical features, syntactic parse features, dependency features and semantic features (Jiang and Zhai, 2007; Kambhatla, 2004; Zhou et al., 2005).
P04-1018	J96-1002	p	Effective training algorithm exists (Berger et al. , 1996) once the set of features a42 a57 a16 a1a33a8 a71a54a8 a71a100a85a68a5 a53 is selected.
C02-1143	P97-1003	o	In order to extract the linguistic features necessary for the model, all sentences were first automatically part-of-speech-tagged using a maximum entropy tagger (Ratnaparkhi, 1998) and parsed using the Collins parser (Collins, 1997).
H05-1102	P04-1015	o	We also employ the voted perceptron algorithm (Freund and Schapire, 1999) and the early update technique as in (Collins and Roark, 2004).
P08-1058	P07-1065	p	Recent work (Talbot and Osborne, 2007b) has demonstrated that randomized encodings can be used to represent n-gram counts for LMs with signficant space-savings, circumventing information-theoretic constraints on lossless data structures by allowing errors with some small probability.
W08-1122	P06-1130	o	Cahill and van Genabith (2006) attain 98.2% coverage and a BLEU score of 0.6652 on the standard WSJ test set (Section 23).
W06-3108	J96-1002	p	In the case of two orientation classes, cj,j is defined as: cj,j = braceleftbigg left, if j < j right, if j > j (4) Then, the reordering model has the form p(cj,j|fJ1,eI1,i,j) A well-founded framework for directly modeling the probability p(cj,j|fJ1,eI1,i,j) is maximum entropy (Berger et al. , 1996).
N01-1010	J96-2004	o	Normally,   :8 is considered a good agreement (Carletta, 1996).
I05-2012	J93-2003	o	(Haruno et al. , 1996; Kay et al. , 1993) applied iterative refinement algorithms to sentence level alignment tasks.
J98-2001	J96-2004	o	"And indeed, the agreement figures went up from K = 0.63 to K = 0.68 (ignoring doubts) when we did so, i.e., within the ""tentative"" margins of agreement according to Carletta (1996) (0.68 <_ x < 0.8)."
N04-2003	J96-1002	o	3 Feature selection Berger et al (1996) proposed an iterative procedure of adding news features to feature set driven by data.
P09-1057	P08-1085	o	The table in Figure 9 shows a comparison of different systems for which tagging accuracies have been reported previously for the 17-tagset case (Goldberg et al., 2008).
N06-1056	J93-2003	o	More specifically, a statistical word alignment model (Brown et al. , 1993) is used to acquire a bilingual lexicon consisting of NL substrings coupled with their translations in the target MRL.
P08-1117	J93-2004	o	In (Bayraktar et al., 1998) the WSJ PennTreebank corpus (Marcus et al., 1993) is analyzed and a very detailed list of syntactic patterns that correspond to different roles of commas is created.
P09-1053	W06-3104	o	These are identical to prior work (Smith and Eisner, 2006; Wang et al., 2007), except that we add a root configuration that aligns the target parent-child pair to null and the head word of the source sentence, respectively.
J04-4002	J93-2003	o	As an alternative to the often used sourcechannel approach (Brown et al. 1993), we directly model the posterior probability Pr(e I 1 | f J 1 ) (Och and Ney 2002).
W07-0812	W95-0107	o	A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification.
W05-0814	P03-1021	p	We wish to minimize this error function, so we select  accordingly: argmin  summationdisplay a E(a)(a, (argmax a p(a, f|e))) (4) Maximizing performance for all of the weights at once is not computationally tractable, but (Och, 2003) has described an efficient one-dimensional search for a similar problem.
D07-1107	N04-3012	o	We use eight similarity measures implemented within the WordNet::Similarity package5, described in (Pedersen et al. , 2004); these include three measures derived from the paths between the synsets in WordNet: HSO (Hirst and St-Onge, 1998), LCH (Leacock and Chodorow, 1998), and WUP (Wu and Palmer, 1994); three measures based on information content: RES (Resnik, 1995), LIN (Lin, 1998), and JCN (Jiang and Conrath, 1997); the gloss-based Extended Lesk Measure LESK, (Banerjee and Pedersen, 2003), and finally the gloss vector similarity measure VECTOR (Patwardan, 2003).
W06-3406	J96-2004	o	The Kappa statistic (Carletta, 1996) is typically used to measure the human interrater agreement.
J05-1003	J96-1002	o	6.4 Feature Selection Methods A number of previous papers (Berger, Della Pietra, and Della Pietra 1996; Ratnaparkhi 1998; Della Pietra, Della Pietra, and Lafferty 1997; McCallum 2003; Zhou et al. 2003; Riezler and Vasserman 2004) describe feature selection approaches for log-linear models applied to NLP problems.
W09-2205	W06-1615	o	Intuitively, if we are able to find good correspondences through linking pivots, then the augmented source data should transfer better to a target domain (Blitzer et al., 2006).
C08-1100	C98-2122	p	4.1 Features We used a dependency structure as the context for words because it is the most widely used and one of the best performing contextual information in the past studies (Ruge, 1997; Lin, 1998).
W03-0303	J97-3002	p	More suitable ways could be bilingual chunk parsing, and refining the bracketing grammar as described in [Wu 1997].
P06-1043	N06-1020	p	Furthermore, use of the self-training techniques described in (McClosky et al. , 2006) raise this to 87.8% (an error reduction of 28%) again without any use of labeled Brown data.
N07-1046	J93-2003	o	3 Bi-Stream HMMs for Transliteration Standard IBM translation models (Brown et al. , 1993) can be used to obtain letter-to-letter translations.
P06-2070	J93-2003	o	The corpus is aligned in the word level using IBM Model4 (Brown et al. , 1993).
D08-1066	N06-1033	o	3.1 Binarizable segmentations (a) Following (Zhang et al., 2006; Huang et al., 2008), every sequence of phrase alignments can be viewed 1For example, if the cut-off on phrase pairs is ten words, all sentence pairs smaller than ten words in the training data will be included as phrase pairs as well.
C96-1078	J93-2003	o	Some o1' l;his research has treated the sentenees as unstructured word sequences to be aligned; this work has primarily involved the acquisition of bilingual lexical correspondences (Chen, 1993), although there has also been a,n attempt to create a full MT system based on such trcat, ment (Brown et al. , 1993).
A00-2007	W95-0107	o	The data was segmented into baseNP parts and nonbaseNP parts in a similar fashion as the data used by (Ramshaw and Marcus, 1995).
W99-0307	J96-2004	o	k -~ P(A) P(E) (3) 1P(E) Carletta (1996) suggests that the units over which the kappa statistic is computed affects the outcome.
W09-0201	C98-2122	o	Concept similarity is often measured by vectors of co-occurrence with context words that are typed with dependency information (Lin, 1998; Curran and Moens, 2002).
P01-1010	P97-1003	o	We should note, however, that most other stochastic parsers do include counts of single nonheadwords: they appear in the backed-off statistics of these parsers (see Collins 1997, 1999; Charniak 1997; Goodman 1998).
D07-1071	W02-1001	o	In Step 3, a simple perceptron update (Collins, 2002) is performed.
P08-1034	P04-1035	o	Pang and Lee (2004) applied two different classifiers to perform sentiment annotation in two sequential steps: the first classifier separated subjective (sentiment-laden) texts from objective (neutral) ones and then they used the second classifier to classify the subjective texts into positive and negative.
P04-1058	P97-1003	p	As a side product, we find empirical evidence to suggest that the effectiveness of rule lexicalization techniques (Collins, 1997; Simaan, 2000) and parent annotation techniques (Klein and Manning, 2003) is due to the fact that both lead to a reduction in perplexity in the automata induced from training corpora.
C94-2198	J92-4003	o	For a class bigram model, find  : V --+ C to maximize ~(T) = ~I/L=I p(wi I(wl))p((wi)l(wi-1)))) Alternatively, perplexity (Jardino an d Adda, 1993) or average mutual information (Brown et al. , 1992) can be used as the characteristic value for optimization.
P04-1020	J96-1002	o	(In our experiments, we use maximum entropy classification (MaxEnt) (Berger et al. , 1996) to train this probability model).
N09-1031	W02-1011	o	Applications have included the categorization of documents by topic (Joachims, 1998), language (Cavnar and Trenkle, 1994), genre (Karlgren and Cutting, 1994), author (Bosch and Smith, 1998), sentiment (Pang et al., 2002), and desirability (Sahami et al., 1998).
W09-0432	P02-1040	o	5 185 the BLEU score (Papineni et al., 2002), and tested on test2008.
P03-2036	J93-2004	o	We performed a comparison between the existing CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al. , 2000), using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al. , 1993) into HPSG-style.
W08-2122	P07-1080	o	2.1 Synchronous derivations The derivations for syntactic dependency trees are the same as specified in (Titov and Henderson, 2007b), which are based on the shift-reduce style parser of (Nivre et al., 2006).
D07-1033	W02-1001	o	This algorithm is proved to converge (i.e. , there are no more updates) in the separable case (Collins, 2002a).1 Thatis,ifthereexistweightvectorU (with ||U|| = 1),  (> 0), and R (> 0) that satisfy: i,y  Y|xi| (xi,yi)U (xi,y)U  , i,y  Y|xi| ||(xi,yi)(xi,y)||  R, the number of updates is at most R2/2.
C08-1145	N03-5008	o	As machine learners we used SVM-light1 (Joachims, 1998) and the MaxEnt decider from the Stanford Classifier2 (Manning and Klein, 2003).
N07-2037	P02-1040	o	We measure translation performance by the BLEU score (Papineni et al, 2002) with one reference for each hypothesis.
D07-1033	W02-1001	o	6.3 Comparison with re-ranking approach Finally, we compared our algorithm with the reranking approach (Collins and Duffy, 2002; Collins, 2002b), where we rst generate the n-best candidates using a model with only local features (the rst model) and then re-rank the candidates using a model with non-local features (the second model).
W01-0706	J93-2004	o	Parsers Precision(a4 ) Recall(a4 ) a5a7a6 (a4 ) a8KM00 a9 93.45 93.51 93.48 a8Hal00 a9 93.13 93.51 93.32 a8CSCL a9 * 93.41 92.64 93.02 a8TKS00 a9 94.04 91.00 92.50 a8ZST00 a9 91.99 92.25 92.12 a8Dej00 a9 91.87 91.31 92.09 a8Koe00 a9 92.08 91.86 91.97 a8Osb00 a9 91.65 92.23 91.94 a8VB00 a9 91.05 92.03 91.54 a8PMP00 a9 90.63 89.65 90.14 a8Joh00 a9 86.24 88.25 87.23 a8VD00 a9 88.82 82.91 85.76 Baseline 72.58 82.14 77.07 2.2 Data Training was done on the Penn Treebank (Marcus et al. , 1993) Wall Street Journal data, sections 02-21.
W09-0209	P06-1101	p	Automatically creating or extending taxonomies for specific domains is then a very interesting area of research (OSullivan et al., 1995; Magnini and Speranza, 2001; Snow et al., 2006).
W09-0424	P03-1021	p	The search across a dimension uses the efficient method of Och (2003).
W03-1706	W95-0107	o	Like baseNP chunking(Church, 1988; Ramshaw & Marcus 1995), content chunk parsing is also a kind of shallow parsing.
E06-1004	J93-2003	o	An open question in SMT is whether there existsclosed formexpressions (whoserepresentation is polynomial in the size of the input) for P (f|e) and the counts in the EM iterations for models 3-5 (Brown et al. , 1993).
W07-0735	P02-1040	o	To further emphasize the importance of morphology in MT to Czech, we compare the standard BLEU (Papineni et al. , 2002) of a baseline phrasebased translation with BLEU which disregards word forms (lemmatized MT output is compared to lemmatized reference translation).
W05-0831	J97-3002	o	4.5 ITG Constraints Another type of reordering can be obtained using Inversion Transduction Grammars (ITG) (Wu, 1997).
W00-1208	J93-2004	o	2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al. , 1993), the Chinese Penn Treebank (Xia et al. , 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000).
P07-1053	P02-1053	o	We follow the approach by Turney (2002), who note that the semantic orientation of an adjective depends on the noun that it modifies and suggest using adjective-noun or adverb-verb pairs to extract semantic orientation.
D07-1080	P06-1091	o	Tillmann and Zhang (2006) trained their feature set using an online discriminative algorithm.
P08-1011	N03-1017	o	In most statistical machine translation (SMT) models (Och et al., 2004; Koehn et al., 2003; Chiang, 2005), some of measure words can be generated without modification or additional processing.
W07-0716	N03-1017	o	??Initial phrase pairs are identified following the procedure typically employed in phrase based systems (Koehn et al. , 2003; Och and Ney, 2004).
D08-1039	D07-1007	p	In Carpuat and Wu (2007), anotherstate-of-the-artWSDengine(acombination of naive Bayes, maximum entropy, boosting and Kernel PCA models) is used to dynamically determine the score of a phrase pair under consideration and, thus, let the phrase selection adapt to the context of the sentence.
D08-1089	J97-3002	p	Coming from the other direction, such observations about phrase reordering between different languages are precisely thekindsoffactsthatparsingapproachestomachine translation are designed to handle and do successfully handle (Wu, 1997; Melamed, 2003; Chiang, 2005).
W98-0701	J93-2004	o	Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files (Miller et al. , 1993), we have counted the occurrences of content words which previously appear in the same discourse file.
P06-1110	P04-1015	n	Although generating training examples in advance without a working parser (Turian & Melamed, 2005) is much faster than using inference (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004), our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor.
N09-2032	J93-2004	o	To determine the target distribution we classified 171 (approximately 5%) randomly selected utterances from the TownInfo data, that were used as a development set.2 In Table 1 we can see that 15.2 % of the trees in the artificial corpus will be NP NSUs.3 4 Data generation We constructed our artificial corpus from sections 2 to 21 of the Wall Street Journal (WSJ) section of the Penn Treebank corpus (Marcus et al., 1993) 2We discarded very short utterances (yes, no, and greetings) since they dont need parsing.
H05-1046	P95-1026	o	There has of course been a large amount of work on the more general problem of word-sense disambiguation, e.g., (Yarowsky 1995) (Kilgarriff and Edmonds 2002).
N09-1066	P08-1093	o	Citation texts have also been used to create summaries of single scientific articles in Qazvinian and Radev (2008) and Mei and Zhai (2008).
E06-1040	P02-1040	p	Properly calculated BLEU scores have been shown to correlate reliably with human judgments (Papineni et al. , 2002).
W93-0310	J90-1003	o	(1989), Wettler & Rapp (1989) and Church & Hanks (1990) describe algorithms which do this.
D08-1085	D07-1090	p	We conclude by noting that English language models currently used in speech recognition (Chelba and Jelinek, 1999) and automated language translation (Brants et al., 2007) are much more powerful, employing, for example, 7-gram word models (not letter models) trained on trillions of words.
P08-1003	P06-1101	o	(Ponzetto and Strube, 2007; Snow et al., 2006)), can be summarized as: [] C [such as|including] I [and|,|.], where I is a potential instance (e.g., Venezuelan equine encephalitis) and C is a potential class label for the instance (e.g., zoonotic diseases), for example in the sentence: The expansion of the farms increased the spread of zoonotic diseases such as Venezuelan equine encephalitis [].
P07-1059	N03-1017	o	4 SMT-Based Query Expansion Our SMT-based query expansion techniques are based on a recent implementation of the phrasebased SMT framework (Koehn et al. , 2003; Och and Ney, 2004).
P98-2127	P90-1034	o	In (Hindle, 1990), a small set of sample results are presented.
P05-1059	J97-3002	o	1 Introduction The Inversion Transduction Grammar (ITG) of Wu (1997) is a syntactically motivated algorithm for producing word-level alignments of pairs of translationally equivalent sentences in two languages.
N07-1022	N03-1017	o	Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al. , 2003).
E09-3005	D07-1112	o	The problem itself has started to get attention only recently (Roark and Bacchiani, 2003; Hara et al., 2005; Daume III and Marcu, 2006; Daume III, 2007; Blitzer et al., 2006; McClosky et al., 2006; Dredze et al., 2007).
W06-0112	W95-0107	o	2 Task Description 2.1 Data Representation Ramshaw and Marcus (1995) gave mainly two kinds of base NPs representation  the open/close bracketing and IOB tagging.
W09-0421	P03-1021	o	The translation system is a factored phrasebased translation system that uses the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models.
P06-2061	P03-1021	o	In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al. , 2003).
W09-2303	J97-3002	o	production rules are typically learned from alignment structures (Wu, 1997; Zhang and Gildea, 2004; Chiang, 2007) or from alignment structures and derivation trees for the source string (Yamada and Knight, 2001; Zhang and Gildea, 2004).
P09-1078	W02-1011	o	Among these methods, SVM is shown to perform better than other methods (Yang and Pedersen, 1997; Pang et al.,  1  2  3   2002).
D08-1079	P08-1094	o	Nenkova and Louis (2008) investigate how summary length and the characteristics of the input influence the summary quality in multi-document summarization.
W05-1510	J96-1002	o	2.3 Probabilistic models for generation with HPSG Some existing studies on probabilistic models for HPSG parsing (Malouf and van Noord, 2004; Miyao and Tsujii, 2005) adopted log-linear models (Berger et al. , 1996).
P08-1007	W05-0909	o	To address this, standard measures like precision and recall could be used, as in some previous research (Banerjee and Lavie, 2005; Melamed et al., 2003).
C00-2100	J93-1003	o	Several techniques and results have been reported on learning subcategorization frames (SFs) from text corpora (Webster and Marcus, 1989; Brent, 1991; Brent, 1993; Brent, 1994; Ushioda et al. , 1993; Manning, 1993; Ersan and Charniak, 1996; Briscoe and Carroll, 1997; Carroll and Minnen, 1998; Carroll and Rooth, 1998).
P08-1047	D07-1073	o	The previous studies, with the exception of Kazama and Torisawa (2007), used smaller gazetteers than ours.
P08-1041	P04-1035	o	In many applications, it has been shown that sentences with subjective meanings are paid more attention than factual ones(Pang and Lee, 2004)(Esuli and Sebastiani, 2006).
E09-1098	C02-1007	o	At the present time, given the key role of window size in determining the selection and apparent strength of associations under the conventional co-occurrence model highlighted here and in the works of Church et al (1991), Rapp (2002), Wang (2005), and Schulte im Walde & Melinger (2008) we would urge that this is an issue which window-driven studies continue to conscientiously address; at the very least, scale is a parameter which findings dependent on distributional phenomena must be qualified in light of.
P08-1094	W04-1013	o	The idea of topic signature terms was introduced by Lin and Hovy (Lin and Hovy, 2000) in the context of single document summarization, and was later used in several multi-document summarization systems (Conroy et al., 2006; Lacatusu et al., 2004; Gupta et al., 2007).
C96-2141	J93-2003	o	In the recent years, there have been a number of papers considering this or similar problems: (Brown et al. , 1990), (Dagan et al. , 1993), (Kay et al. , 1993), (Fung et al. , 1993).
J02-3004	J92-4003	o	Classes can be induced directly from the corpus using distributional clustering (Pereira, Tishby, and Lee 1993; Brown et al. 1992; Lee and Pereira 1999) or taken from a manually crafted taxonomy (Resnik 1993).
D09-1024	D07-1006	o	In the first set of experiments, we compare two settings of our UALIGN system with other aligners, GIZA++ (Union) (Och and Ney, 2003) and LEAF (with 2 iterations) (Fraser and Marcu, 2007).
W04-0819	P97-1003	o	These sentences were parsed with the Collins parser (Collins, 1997).
D08-1024	P03-1021	o	2 Learning algorithm The translation model is a standard linear model (Och and Ney, 2002), which we train using MIRA (Crammer and Singer, 2003; Crammer et al., 2006), following Watanabe et al.
D07-1096	D07-1112	o	Instead of assigning HEAD and DEPREL in a single step, some systems use a two-stage approach for attaching and labeling dependencies (Chen et al. , 2007; Dredze et al. , 2007).
H05-1025	J92-1002	o	A standard solution is to use a weighted linear mixture of N-gram models, 1  n  N, (Brown et al. , 1992).
D07-1049	P07-1065	o	As noted in Talbot and Osborne (2007), errors for this log-frequency BF scheme are one-sided: frequencies will never be underestimated.
C00-1078	J93-2003	o	These transtbr rules are pairs of corresponding rooted substructures, where a substructure (Matsumoto et al. , 1993) is a connected set of arcs and nodes.
P08-1058	P07-1065	o	However, if we are willing to accept that occasionally our model will be unable to distinguish between distinct n-grams, then it is possible to store each parameter in constant space independent of both n and the vocabulary size (Carter et al., 1978), (Talbot and Osborne, 2007a).
P98-1006	J97-3002	n	The work reported in Wu (1997), which uses an inside-outside type of training algorithm to learn statistical contextfree transduction, has a similar motivation to the current work, but the models we describe here, being fully lexical, are more suitable for direct statistical modelling.
H05-1022	P03-1021	o	The hallucination process is motivated by the use of NULL alignments into Markov alignment models as done by (Och and Ney, 2003).
P98-2124	J92-4003	n	Our method is a natural extension of those proposed in (Brown et al. , 1992) and (Li and Abe, 1996), and overcomes their drawbacks while retaining their advantages.
P05-1038	P97-1003	p	Previous work for English (e.g. , Magerman, 1995; Collins, 1997) has shown that lexicalization leads to a sizable improvement in parsing performance.
I08-2124	P06-1027	o	Reported work includes improved model variants (e.g., Jiao et al., 2006) and applications such as web data extraction (Pinto et al., 2003), scientific citation extraction (Peng and McCallum, 2004), word alignment (Blunsom and Cohn, 2006), and discourselevel chunking (Feng et al., 2007).
P09-1109	W02-1001	o	3.3 Perceptron learning of feature weights As we saw above, our model is a linear model with the global weight vector w acting as the coefficient vector, and hence various existing techniques can be exploited to optimize w. In this paper, we use the averaged perceptron learning (Collins, 2002; Freund and Schapire, 1999) to optimize w on a training corpus, so that the system assigns the highest score to the correct coordination tree among all possible trees for each training sentence.
D09-1024	D07-1006	o	Besides precision, recall and (balanced) F-measure, we also include an F-measure variant strongly biased towards recall (#0B=0.1), which (Fraser and Marcu, 2007) found to be best to tune their LEAF aligner for maximum MT accuracy.
J07-2003	P03-1021	o	4.2 Features For our experiments, we use a feature set analogous to the default feature set of Pharaoh (Koehn, Och, and Marcu 2003).
N04-1019	P02-1040	p	In machine translation, the rankings from the automatic BLEU method (Papineni et al. , 2002) have been shown to correlate well with human evaluation, and it has been widely used since and has even been adapted for summarization (Lin and Hovy, 2003).
P09-2010	J93-2004	o	3.1 Data The English data set consists of the Wall Street Journal sections 2-24 of the Penn treebank (Marcus et al., 1993), converted to dependency format.
P09-1050	P06-1101	o	Snow etal (Snow et al., 2006) use known hypernym/hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns.
W06-3601	J97-3002	n	Besides, our model, as being linguistically motivated, is also more expressive than the formally syntax-based models of Chiang (2005) and Wu (1997).
E09-3008	P03-1021	o	The tools used are the Moses toolkit (Koehn et al., 2007) for decoding and training, GIZA++ for word alignment (Och and Ney, 2003), and SRILM (Stolcke, 2002) for language models.
I08-1041	W02-1011	p	Unigram models have been previously shown to give good results in sentiment classification tasks (Kennedy and Inkpen, 2006; Pang et al., 2002): unigram representations can capture a variety of lexical combinations and distributions, including those of emotion words.
W94-0103	J93-1003	o	The algorithm is based on the Machine Learning method for word categorisation, inspired by the well known study on basic-level categories \[Rosch, 1978\], presented in \[Basili et al, 1993a\].
C96-2141	J93-2003	o	A sinfilar approach has been chosen by (Da.gan et al. , 1993).
W05-1504	P97-1003	o	In parsing, the most relevant previous work is due to Collins (1997), who considered three binary features of the intervening material: did it contain (a) any word tokens at all, (b) any verbs, (c) any commas or colons?
P09-1031	P06-1101	o	We compare system performance between (Snow et al., 2006) and our framework in Section 5.
P08-1047	D07-1073	o	The small differences from their work are: (1) We used characters as the unit as we described above, (2) While Kazama and Torisawa (2007) checked only the word sequences that start with a capitalized word and thus exploitedthecharacteristicsofEnglishlanguage, we checked the matching at every character, (3) We used a TRIE to make the look-up efcient.
P07-1053	P02-1053	o	However, we do not rely on linguistic resources (Kamps and Marx, 2002) or on search engines (Turney and Littman, 2003) to determine the semantic orientation, but rather rely on econometrics for this task.
W07-1516	W96-0213	p	More recent work has achieved state-of-the-art results with Maxi101 mum entropy conditional Markov models (MaxEnt CMMs, or MEMMs for short) (Ratnaparkhi, 1996; Toutanova & Manning, 2000; Toutanova et al. , 2003).
W07-0406	N03-1017	p	However, attempts to retrofit syntactic information into the phrase-based paradigm have not met with enormous success (Koehn et al. , 2003; Och et al. , 2003)1, and purely phrase-based machine translation systems continue to outperform these syntax/phrase-based hybrids.
D09-1119	W95-0107	o	5.2 NP Chunking The goal of this task (Marcus and Ramshaw, 1995) is the identification of non-recursive NPs.
P07-1036	N06-1041	o	(Haghighi and Klein, 2006) extends the dictionarybased approach to sequential labeling tasks by propagating the information given in the seeds with contextual word similarity.
P04-1015	W02-1001	o	Freund and Schapire (1999) discuss how the theory for classification problems can be extended to deal with both of these questions; Collins (2002) describes how these results apply to NLP problems.
W09-2413	D07-1007	p	Several studies have demonstrated that for instance Statistical Machine Translation (SMT) benefits from incorporating a dedicated WSD module (Chan et al., 2007; Carpuat and Wu, 2007).
E09-1031	P08-1101	o	Finally, Zhang and Clark (2008) achieve an SF of 95.90% and a TF of 91.34% by 10-fold cross validation using CTB data.
N09-3016	N03-1017	o	The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003).
E06-1011	W02-1001	p	An online learning algorithm considers a single training instance for each update to the weight vector w. We use the common method of setting the final weight vector as the average of the weight vectors after each iteration (Collins, 2002), which has been shown to alleviate overfitting.
C04-1060	J97-3002	o	In our experiments we use a grammar with a start symbol S, a single preterminal C, and two nonterminals A and B used to ensure that only one parse can generate any given word-level alignment (ignoring insertions and deletions) (Wu, 1997; Zens and Ney, 2003).
H05-1059	J96-1002	o	3 Maximum Entropy Classifier For local classifiers, we used a maximum entropy model which is a common choice for incorporating various types of features for classification problems in natural language processing (Berger et al. , 1996).
W09-0106	P08-1065	o	(Jiampojamarn et al., 2008) and (Bartlett et al., 2008) do worse on the English test data than they do on German, Dutch, or French.
N03-1028	J96-1002	o	The sequential classi cation approach can handle many correlated features, as demonstrated in work on maximum-entropy (McCallum et al. , 2000; Ratnaparkhi, 1996) and a variety of other linear classi ers, including winnow (Punyakanok and Roth, 2001), AdaBoost (Abney et al. , 1999), and support-vector machines (Kudo and Matsumoto, 2001).
W08-0906	N03-1003	o	While word and phrasal paraphrases can be assimilated to the well-studied notion of synonymy, sentencelevel paraphrasingis moredifficult to grasp and cannot be equated with word-for-word or phrase-by-phrase substitution since it might entail changes in the structure of the sentence (Barzilay and Lee, 2003).
D09-1009	P06-1027	o	We use Entropy Regularization (ER) (Jiao et al., 2006) to leverage unlabeled instances.7 We weight the ER term by choosing the best8 weight in {103,102,101,1,10} multiplied by #labeled#unlabeled for each data set and query selection method.
C08-1107	N03-1003	o	Some works focused on learning rules from comparable corpora, containing comparable documents such as different news articles from the same date on the same topic (Barzilay and Lee, 2003; Ibrahim et al., 2003).
P09-1028	W02-1011	p	In their seminal work, (Pang et al., 2002) demonstrated that supervised learning signi cantly outperformed a competing body of work where hand-crafted dictionaries are used to assign sentiment labels based on relative frequencies of positive and negative terms.
P06-2092	J93-2003	o	3.2 Word Order Differences Another problem that has been noticed as early as 1993 with the first research on word alignment (Brown et al. , 1993) concerns the differences in word order between source and target language.
W07-2220	D07-1013	o	Acknowledgments I want to thank my fellow organizers of the shared task, Johan Hall, Sandra Kubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret, whoarealsoco-authorsofthelongerpaperonwhich this paper is partly based (Nivre et al. , 2007).
N09-1068	P07-1033	o	2.4 Formalization of (Daume III, 2007) As mentioned earlier, our model is equivalent to that presented in (Daume III, 2007), and can be viewed as a formal version of his model.2 In his presentation, the adapation is done through feature augmentation.
P08-2063	P06-1014	o	Navigli (2006) has induced clusters by mapping WordNet senses to a more coarse-grained lexical resource.
D08-1011	P07-1040	o	Similar to (Rosti et al., 2007), each word in the confusion network is associated with a word posterior probability.
W03-0302	J93-2003	o	To avoid this problem, we sample from a space of probable alignments, as is done in IBM models 3 and above (Brown et al. , 1993), and weight counts based on the likelihood of each alignment sampled under the current probability model.
W09-1703	P02-1053	o	Turney (Turney, 2001; Turney, 2002) reported that the NEAR operator outperformed simple page co-occurrence for his purposes; our early experiments informally showed the same for this work.
E09-1062	P08-1094	o	For the first set of experiments, we divide all inputs based on the mean value of the average system scores as in (Nenkova and Louis, 2008).
P97-1063	J93-1003	o	1 Introduction Over the past decade, researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation (Brown et al. , 1988; Brown et al. , 1990; Brown et al. , 1993a).
N04-1026	J96-2004	o	The two annotators agreed on the annotations of 385/453 turns, achieving 84.99% agreement, with Kappa = 0.68.2 This inter-annotator agreement exceeds that of prior studies of emotion annotation in naturally occurring speech 2a3a5a4a7a6a8a6a9a4a11a10a13a12a15a14a17a16a19a18a21a20a22a12a23a14a25a24a26a18 a27 a20a22a12a23a14a25a24a26a18 (Carletta, 1996).
I08-1035	W04-1013	o	4.2 A ROUGE Based Approach ROUGE (Lin, 2004) is the standard automatic evaluation metric in the Summarization community.
C90-3028	P88-1012	p	Recently, an elegant approach to inference in discourse interpretation has been developed at a number of sites (e.g. , ltobbs et al. , 1988; Charniak and Goldman, 1988; Norvig, 1987), all based on tim notion of abduction, and we have begun to explore its potential application to machine translation.
W04-1114	J90-1003	o	The typical problems like doctor-nurse (Church and Hanks 1990) could be avoided by using such information.
P07-1038	P02-1040	o	Reference-based metrics such as BLEU (Papineni et al. , 2002) have rephrased this subjective task as a somewhat more objective question: how closely does the translation resemble sentences that are known to be good translations for the same source?
N07-2022	P03-1021	o	In order to improve translation quality, this tuning can be effectively performed by minimizing translation error over a development corpus for which manually translated references are available (Och, 2003).
J99-2004	J93-2004	o	2.2 Statistical Parsers Pioneered by the IBM natural language group (Fujisaki et al. 1989) and later pursued by, for example, Schabes, Roth, and Osborne (1993), Jelinek et al.
J93-3004	J90-1003	o	For example, Church and Hanks (1990) describe the use of the mutual information index for this purpose (cf.
P03-1013	P97-1003	n	Section 5 presents an error analysis for Collinss (1997) lexicalized model, which shows that the head-head dependencies used in this model fail to cope well with the flat structures in Negra.
P08-1114	N06-1032	p	Riezler and Maxwell (2006) do not achieve higher BLEU scores, but do score better according to human grammaticality judgments for in-coverage cases.
N07-1008	N06-1002	p	Also, slightly restating the advantages of phrase-pairs identified in (Quirk and Menezes, 2006), these blocks are effective at capturing context including the encoding of non-compositional phrase pairs, and capturing local reordering, but they lack variables (e.g. embedding between ne . . .pas in French), have sparsity problems, and lack a strategy for global reordering.
P09-1104	J97-3002	o	1 Introduction Inversion transduction grammar (ITG) constraints (Wu, 1997) provide coherent structural constraints on the relationship between a sentence and its translation.
C02-1125	J93-1003	o	The value of Dist(D(T)) can be defined in various ways, and they found that using log-likelihood ratio (see Dunning 1993) worked best which is represented as follows: 0 # log )(# log D K k TD k k i M ii i i M ii i  == , where k i and K i are the frequency of a word w i in D(W) and D 0 respectively, and {w 1,,w M } is the set of all words in D 0 . As stated in introduction, Dist(D(T)) is normalized by the baseline function, which is referred as B Dist () here.
A94-1006	J93-1007	o	3.4 Related work and issues for future research Smadja (1992) and van der Eijk (1993) describe term translation methods that use bilingual texts that were aligned at the sentence level.
I08-2101	A00-2024	p	al., 1994), compression of sentences with Automatic Translation approaches (Knight and Marcu, 2000), Hidden Markov Model (Jing and McKeown, 2000), Topic Signatures based methods (Lin and Hovy, 2000, Lacatusu et al., 2006) are among the most popular techniques that have been used in the summarization systems of this category.
P06-1110	P04-1015	o	The left-to-right parser would likely improve if we were to use a left-corner transform (Collins & Roark, 2004).
J04-1003	P95-1026	p	A variety of classifiers have been employed for this task (see Mooney [1996] and Ide and Veronis [1998] for overviews), the most popular being decision lists (Yarowsky 1994, 1995) and naive Bayesian classifiers (Pedersen 2000; Ng 1997; Pedersen and Bruce 1998; Mooney 1996; Cucerzan and Yarowsky 2002).
J95-4004	A92-1018	o	Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g. , Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994).
P93-1034	J92-4003	o	(Brown et al. 1992) where the same idea of improving generalization and accuracy by looking at word classes instead of individual words is used.
D07-1027	P04-1041	o	3.2 F-Structure Based NLD Recovery (Cahill et al. , 2004) presented a NLD recovery algorithm operating at LFG f-structure for treebankbased LFG approximations.
E09-1048	W04-1013	o	ROUGE (Lin, 2004), a recall-oriented evaluation package for automatic summarization.
A97-2010	P95-1026	o	A Broad-Coverage Word Sense Tagger Dekang Lin Department of Computer Science University of Manitoba Winnipeg, Manitoba, Canada R3T 2N2 lindek@cs.umanitoba.ca Previous corpus-based Word Sense Disambiguation (WSD) algorithms (Hearst, 1991; Bruce and Wiebe, 1994; Leacock et al. , 1996; Ng and Lee, 1996; Yarowsky, 1992; Yarowsky, 1995) determine the meanings of polysemous words by exploiting their local contexts.
D09-1075	D07-1031	o	4.1 Variational Bayes Beal (2003) and Johnson (2007) describe variational Bayes for hidden Markov model in detail, which can be directly applied to our bilingual model.
E06-1004	J93-2003	o	For a detailed introduction to IBM translation models, please see (Brown et al. , 1993).
W06-3123	N03-1017	o	On smaller data sets (Koehn et al. , 2003) the joint model shows performance comparable to the standard model, however the joint model does not reach the level of performance of the stan156 EN-ES ES-EN Joint 3-gram, dl4 20.51 26.64 5-gram, dl6 26.34 27.17 + lex.
D08-1104	D07-1050	o	They are not used in LN, but they are known to be useful for WSD (Tanaka et al., 2007; Magnini et al., 2002).
P99-1079	J93-2004	o	3 Evaluation of Algorithms All four algorithms were run on a 3900 utterance subset of the Penn Treebank annotated corpus (Marcus et al. , 1993) provided by Charniak and Ge (1998).
C02-1101	W96-0213	o	For example, many statistical part-of-speech (POS) taggers have been developed and they use corpora as the training data to obtain statistical information or rules (Brill, 1995; Ratnaparkhi, 1996).
W04-2403	J93-2004	o	4 The Experiments For the experiments, we used PropBank (www.cis.upenn.edu/ace) along with PennTreeBank5 2 (www.cis.upenn.edu/treebank) (Marcus et al. , 1993).
P07-1005	N03-1017	p	To perform translation, state-of-the-art MT systems use a statistical phrase-based approach (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) by treating phrases as the basic units of translation.
W08-2102	W02-1001	o	1 Introduction In global linear models (GLMs) for structured prediction, (e.g., (Johnson et al., 1999; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003; Taskar et al., 2004)), the optimal label y for an input x is y = arg max yY(x) w f(x,y) (1) where Y(x) is the set of possible labels for the input x; f(x,y)  Rd is a feature vector that represents the pair (x,y); and w is a parameter vector.
H05-1019	W04-1013	o	The results of the comparison with ROUGE-N (Lin and Hovy, 2003; Lin, 2004a; Lin, 2004b), ROUGE-S(U) (Lin, 2004b; Lin and Och, 2004) and ROUGE-L (Lin, 2004a; Lin, 2004b) show that our method correlates more closely with human evaluations and is more robust.
W09-0805	P08-1079	o	While in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types (Davidov et al., 2007; Davidov and Rappoport, 2008a; Davidov and Rappoport, 2008b).
W09-0809	N03-1017	o	Separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as a traditional PSMT system (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005).
W04-3112	A92-1018	o	The initial phase relies on a parser that draws on the SPECIALIST Lexicon (McCray et al. 1994) and the Xerox Part-of-Speech Tagger (Cutting et al. 1992) to produce an underspecified categorial analysis.
W98-1113	J92-4003	n	Clustering algorithms have been previously shown to work fairly well for the classification of words into syntactic and semantic classes (Brown et al. 1992), but determining the optimum number of classes for a hierarchical cluster tree is an ongoing difficult problem, particularly without prior knowledge of the item classification.
E09-3005	W06-1615	o	4.2 Further practical issues of SCL In practice, there are more free parameters and model choices (Ando and Zhang, 2005; Ando, 2006; Blitzer et al., 2006; Blitzer, 2008) besides the ones discussed above.
J00-2004	J93-1003	o	Until now, translation models have been evaluated either subjectively (e.g. White and O'Connell 1993) or using relative metrics, such as perplexity with respect to other models (Brown et al. 1993b).
P97-1029	A92-1018	o	There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al. , 1992; DeRose, 1988), constraint-based techniques (Karlsson et al. , 1995; Voutilainen, 1995b; Voutilainen, Heikkil/i, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and KuruSz, 1994; Oflazer and Till 1996) and transformation-based techniques (Brilt, 1992; Brill, 1994; Brill, 1995).
W05-1512	P97-1003	o	With automatic refinement it is harder to guarantee improved performance than with manual refinements (Klein and Manning, 2003) or with refinements based on direct lexicalization (Magerman (1995), Collins (1996), Charniak (1997), etc.).
W05-1208	J93-2003	o	This differs from typical generative settings for IR and MT (Ponte and croft, 1998; Brown et al. , 1993), where all conditioned events are disjoint by construction.
W01-0712	W95-0107	o	Standard data sets for machine learning approaches to this task were put forward by Ramshaw and Marcus (1995).
N06-1033	N04-1035	o	1 Introduction Several recent syntax-based models for machine translation (Chiang, 2005; Galley et al. , 2004) can be seen as instances of the general framework of synchronous grammars and tree transducers.
H05-1036	J97-3002	o	These techniques included unweighted FS morphology, conditional random fields (Lafferty et al. , 2001), synchronous parsers (Wu, 1997; Melamed, 2003), lexicalized parsers (Eisner and Satta, 1999),22 partially supervised training `a la (Pereira and Schabes, 1992),23 and grammar induction (Klein and Manning, 2002).
H05-1009	W96-0213	o	We generate POS tags using the MXPOST tagger (Ratnaparkhi, 1996) for English and Chinese, and Connexor for Spanish.
N06-1031	N04-1035	o	In this work, we employ a syntax-based model that applies a series of tree/string (xRS) rules (Galley et al. , 2004; Graehl and Knight, 2004) to a source language string to produce a target language phrase structure tree.
P06-2089	J96-1002	o	One such approach is maximum entropy classification (Berger et al. , 1996), which we use in the form of a library implemented by Tsuruoka1 and used in his classifier-based parser (Tsuruoka and Tsujii, 2005).
D09-1123	J96-1002	o	DTM2, introduced in (Ittycheriah and Roukos, 2007), expresses the phrase-based translation task in a unified log-linear probabilistic framework consisting of three components: (i) a prior conditional distribution P0(.|S), (ii) a number of feature functions i() that capture the translation and language model effects, and (iii) the weights of the features i that are estimated under MaxEnt (Berger et al., 1996), as in (1): P(T|S) = P0(T,J|S)Z expsummationdisplay i ii(T,J,S) (1) Here J is the skip reordering factor for the phrase pair captured by i() and represents the jump from the previous source word, and Z is the per source sentence normalization term.
N07-1038	P02-1047	o	The effectiveness of these features for recognition of discourse relations has been previously shown by Marcu and Echihabi (2002).
P97-1056	J92-4003	o	An exception is the use of similarity for alleviating the sparse data problem in language modeling (Essen & Steinbiss, 1992; Brown et al. , 1992; Dagan et al. , 1994).
W99-0617	J92-4003	o	(Black et al. , 1992; Magerman, 1994)) and view the POS tags and word identities as two separate sources of information.
P06-1077	J93-2003	n	1 Introduction Phrase-based translation models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004), which go beyond the original IBM translation models (Brown et al. , 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations.
I05-2027	W04-1013	o	These linguistically-motivated trimming rules (Dorr et al. , 2003; Zajic et al. , 2004) iteratively remove constituents until a desired sentence compression rate is reached.
P07-1031	J93-2004	p	1 Introduction The Penn Treebank (Marcus et al. , 1993) is perhaps the most in uential resource in Natural Language Processing (NLP).
P09-2011	P04-1015	o	To tackle this problem, we defined 2The best results of Collins and Roark (2004) (LR=88.4%, LP=89.1% and F=88.8%) are achieved when the parser utilizes the information about the final punctuation and the look-ahead.
P07-1011	J93-2003	o	Second, it can be applied to control the quality of parallel bilingual sentences mined from the Web, which are critical sources for a wide range of applications, such as statistical machine translation (Brown et al. , 1993) and cross-lingual information retrieval (Nie et al. , 1999).
E09-1007	D07-1074	o	However, most of them do not build a NEs resource but exploit external gazetteers (Bunescu and Pasca, 2006), (Cucerzan, 2007).
W07-1001	J93-2004	o	The CDR (Morris, 1993) is assigned with access to clinical and cognitive test information, independent of performance on the battery of neuropsychological tests used for this research study, and has been shown to have high expert inter-annotator reliability (Morris et al. , 1997).
P07-1082	J93-2003	o	(2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al. , 1993) with phonemebased alignments using direct probabilities.
H05-1075	P03-1001	o	2 Related Work Question Answering has attracted much attention from the areas of Natural Language Processing, Information Retrieval and Data Mining (Fleischman et al. , 2003; Echihabi et al. , 2003; Yang et al. , 2003; Hermjakob et al. , 2002; Dumais et al. , 2002; Hermjakob et al. , 2000).
D09-1058	W96-0213	o	English POS tags were assigned by MXPOST (Ratnaparkhi, 1996), which was trained on the training data described in Section 4.1.
N09-1001	W02-1011	o	Automatic identification of subjective content often relies on word indicators, such as unigrams (Pang et al., 2002) or predetermined sentiment lexica (Wilson et al., 2005).
W01-1410	J93-2003	o	We carefully implemented the original Grammar Association system described in (Vidal et al. , 1993), tuned empirically a couple of smoothing parameters, trained the models and, finally, obtained an a119a21a120 a100 a104a122a121 of correct translations.9 Then, we studied the impact of: (1) sorting, as proposed in Section 3, the set of sentences presented to ECGI; (2) making language models deterministic and minimum; (3) constraining the best translation search to those sentences whose lengths have been seen, in the training set, related to the length of the input sentence.
W06-3107	J93-2003	o	Nevertheless, in the problem described in this article, the source and the target sentences are given, and we are focusing on the optimization of the aligment a. The translation probability Pr(f,a|e) can be rewritten as follows: Pr(f,a|e) = Jproductdisplay j=1 Pr(fj,aj|fj11,aj11,eI1) = Jproductdisplay j=1 Pr(aj|fj11,aj11,eI1) Pr(fj|fj11,aj1,eI1) (2) The probability Pr(f,a|e) can be estimated by using the word-based IBM statistical alignment models (Brown et al. , 1993).
W08-0410	D07-1091	p	For example, factored translation models (Koehn and Hoang, 2007) retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features.
W97-0105	J93-2004	o	Slrs Parse Base (Black et al. , 1993a) is 1.76.
D07-1023	N07-1020	p	In particular, we have implemented an unsupervised morphological analyzer that outperforms Goldsmith s (2001) Linguistica and Creutz and Lagus s (2005) Morfessor for our English and Bengali datasets and compares favorably to the bestperforming morphological parsers in MorphoChallenge 20053 (see Dasgupta and Ng (2007)).
W05-1515	P04-1015	o	Training discriminative parsers is notoriously slow, especially if it requires generating examples by repeatedly parsing the treebank (Collins & Roark, 2004; Taskar et al. , 2004).
D09-1093	D07-1090	o	3.3 Language Model We estimate P(s) using n-gram LMs trained on data from the Web, using Stupid Backoff (Brants et al., 2007).
D09-1038	N06-1033	o	Generally, two edges can be re-combined if they satisfy the following two constraints:  1) the LHS (left-hand side) nonterminals are identical and the sub-alignments are the same (Zhang et al., 2006); and 2) the boundary words 1  on both sides of the partial translations are equal between the two edges (Chiang, 2007).
D07-1080	N03-1017	o	Second, the word alignment is refined by a grow-diag-final heuristic (Koehn et al. , 2003).
P00-1060	P97-1003	o	1 Introduction In the field of statistical parsing, various probabilistic evaluation models have been proposed where different models use different feature types [Black, 1992] [Briscoe, 1993] [Brown, 1991] [Charniak, 1997] [Collins, 1996] [Collins, 1997] [Magerman, 1991] [Magerman, 1992] [Magerman, 1995] [Eisner, 1996].
P06-1055	P05-1010	n	As one can see in Table 4, the resulting parser ranks among the best lexicalized parsers, beating those of Collins (1999) and Charniak and Johnson (2005).8 Its F1 performance is a 27% reduction in error over Matsuzaki et al.
E09-1087	P07-1096	p	As a result of this tuning, our (fully supervised) version of the Morce tagger gives the best accuracy among all single taggers for Czech and also very good results for English, being beaten only by the tagger (Shen et al., 2007) (by 0.10 % absolute) and (not significantly) by (Toutanova et al., 2003).
W08-0304	P03-1021	p	While the former is piecewise constant and thus cannot be optimized using gradient techniques, Och (2003) provides an approach that performs such training efficiently.
P08-2056	P07-1010	o	Artificial ungrammaticalities have been used in various NLP tasks (Smith and Eisner, 2005; Okanohara and Tsujii, 2007) The idea of an automatically generated ungrammatical treebank was proposed by Foster (2007).
W96-0305	C94-2113	o	Dolan (1994) described a heuristic approach to forming unlabeled clusters of closely related senses in a MRD.
C08-1101	D07-1113	o	An application of the idea of alternative targets can be seen in Kim and Hovys (2007) work on election prediction.
C04-1066	W95-0107	o	Table 2 shows the unknown word tags for chunking, which are known as the IOB2 model (Ramshaw and Marcus, 1995).
P96-1021	J93-2003	o	Such linguistic-preprocessing techniques could 1Various models have been constructed by the IBM team (Brown et al. , 1993).
D07-1033	W02-1001	o	In this paper, we follow this line of research and try to solve the problem by extending Collins perceptron algorithm (Collins, 2002a).
N06-1025	N04-3012	o	In addition, we use the measure from Resnik (1995), which is computed using an intrinsic information content measure relying on the hierarchical structure of the category tree (Seco et al. , 2004).
C00-1064	J93-2003	p	In statistical machine translation, IBM 1~5 models (Brown et al. , 1993) based on the source-chmmel model have been widely used and revised for many language donmins and applications.
P05-1067	J93-2003	p	1 Introduction Statistical approaches to machine translation, pioneered by (Brown et al. , 1993), achieved impressive performance by leveraging large amounts of parallel corpora.
W05-1609	P85-1008	o	We adopt their idea of an utterance as a description, generated from a communicative goal, and also use an ontologically promiscuous formalism for representing meaning [Hobbs, 1985].
J04-4002	P03-1021	p	An efficient algorithm for performing this tuning for a larger number of model parameters can be found in Och (2003).
W05-0709	J96-1002	o	SEP/epsilon a/A# epsilon/# a/epsilon a/epsilon b/epsilon b/B UNK/epsilon c/C b/epsilon c/BC e/+E epsilon/+ d/epsilon d/epsilon epsilon/epsilon b/AB# b/A#B# e/+DE c/epsilon d/BCD e/+D+E Figure 1: Illustration of dictionary based segmentation finite state transducer 3.1 Bootstrapping In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al. , 1996).
W06-3602	J97-3002	p	The efficient block alignment algorithm in Section 4 is related to the inversion transduction grammar approach to bilingual parsing described in (Wu, 1997): in both cases the number of alignments is drastically reduced by introducing appropriate re-ordering restrictions.
W97-0203	J93-1003	o	This set of words (rooted primarily in the verbs of the set) corresponds to the (Levin, 1993) Characterize (class 29.2), Declare (29.4), Admire (31.2), and Judgment verbs (33) and hence may have particular syntactic and semantic patterning.
H05-1099	P97-1003	o	Perhaps the most widely accepted convention is that of ignoring punctuation for the purposes of assigning constituent span, under the perspective that, fun788 Phrase Evaluation Scenario System Type (a) (b) (c) Modified All 98.37 99.72 99.72 Truth VP 92.14 98.70 98.70 Li and Roth All 94.64 (2001) VP 95.28 Collins (1997) All 92.16 93.42 94.28 VP 88.15 94.31 94.42 Charniak All 93.88 95.15 95.32 (2000) VP 88.92 95.11 95.19 Table 1: F-measure shallow bracketing accuracy under three different evaluation scenarios: (a) baseline, used in Li and Roth (2001), with original chunklink script converting treebank trees and context-free parser output; (b) same as (a), except that empty subject NPs are inserted into every unary SVP production; and (c) same as (b), except that punctuation is ignored for setting constituent span.
P07-1091	N03-1017	o	The implementation is similar to the idea of lexical weight in (Koehn et al. , 2003): all points in the alignment matrices of the entire training corpus are collected to calculate the probabilistic distribution, P(t|s), of some TL word 3Some readers may prefer the expression the subtree rooted at node N to node N. The latter term is used in this paper for simplicity.
P97-1031	A92-1018	o	Second, the automatic approach, in which the model is automatically obtained from corpora (either raw or annotated) 1, and consists of n-grams (Garside et al. , 1987; Cutting et ah, 1992), rules (Hindle, 1989) or neural nets (Schmid, 1994).
W09-0418	P03-1021	o	Minimum error rate training (MERT) with respect to BLEU score was used to tune the decoders parameters, and performed using the technique proposed in (Och, 2003).
W99-0629	J93-2004	o	The data for all our experiments was extracted from the Penn Treebank II Wall Street Journal (WSJ) corpus (Marcus et al. , 1993).
P06-1056	P95-1026	o	Determining the sense of an ambiguous word, using bootstrapping and texts from a different language was done by Yarowsky (1995), Hearst (1991), Diab (2002), and Li and Li (2004).
W09-0423	N03-1017	o	4 Architecture of the SMT system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp(e|f) = argmaxe {exp(summationdisplay i ihi(e,f))} (1) The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002).
J06-4003	J93-1003	o	The usefulness of likelihood ratios for collocation detection has been made explicit by Dunning (1993) and has been confirmed by an evaluation of various collocation detection methods carried out by Evert and Krenn (2001).
N01-1010	J96-2004	o	11 This low agreement ratio is also re ected in a measure called the  statistic (Carletta, 1996;; Bruce and Wiebe, 1998;; Ng et al. , 1999).
P05-2004	W95-0107	o	This segmentation task can be achieved by assigning words in a sentence to one of three tokens: B for Begin-NP, I for Inside-NP, or O for OutsideNP (Ramshaw and Marcus, 1995).
P03-1013	P97-1003	o	The reader is referred to Schmid (2000) and Collins (1997) for details.
C08-1015	D07-1013	o	A simple example is shown in Figure 1, where the arc between a and hat indicates that hat is the head of a. Current statistical dependency parsers perform better if the dependency lengthes are shorter (McDonald and Nivre, 2007).
W03-0401	J96-1002	o	A possible solution to this problem is to directly estimate p(A|w) by applying a maximum entropy model (Berger et al. , 1996).
N09-1034	N06-1041	o	This has been shown both in supervised settings (Roth and Yih, 2004; Riedel and Clarke, 2006) and unsupervised settings (Haghighi and Klein, 2006; Chang et al., 2007) in which constraints are used to bootstrap the model.
P07-1038	W05-0904	o	In addition to adapting the idea of Head Word Chains (Liu and Gildea, 2005), we also compared the input sentences argument structures against the treebank for certain syntactic categories.
P01-1039	W96-0213	o	We use the beam search technique of (Ratnaparkhi, 1996) to search the space of all hypotheses.
P08-1042	J93-2004	o	Treebank (Marcus et al., 1993), six of which are errors.
C08-2005	N03-1017	o	1 Introduction In phrase-based statistical machine translation (Koehn et al., 2003) phrases extracted from word-aligned parallel data are the fundamental unit of translation.
J00-3003	J96-1002	o	Automatic segmentation of spontaneous speech is an open research problem in its own right (Mast et al. 1996; Stolcke and Shriberg 1996).
W02-1304	P95-1026	o	In another line of research, (Yarowsky, 1995) and (Blum and Mitchell, 1998) have shown that it is possible to reduce the need for supervision with the help of large amounts of unannotated data.
P04-1049	J96-2004	o	Inter-annotator agreement was determined for six pairs of two annotators each, resulting in kappa values (Carletta (1996)) ranging from 0.62 to 0.82 for the whole database (Carlson et al.
W02-0301	J96-1002	p	Support Vector Machines (SVMs) (Vapnik, 1995) and Maximum Entropy (ME) method (Berger et al. , 1996) are powerful learning methods that satisfy such requirements, and are applied successfully to other NLP tasks (Kudo and Matsumoto, 2000; Nakagawa et al. , 2001; Ratnaparkhi, 1996).
E09-1043	D07-1091	o	4.1 Training The training procedure is identical to the factored phrase-based training described in (Koehn and Hoang, 2007).
A00-1012	J96-2004	o	"Carletta mentions this problem, asking what the difference would be if the kappa statistic were computed across ""clause boundaries, transcribed word boundaries, and transcribed phoneme boundaries"" (Carletta, 1996, p. 252) rather than the sentence boundaries she suggested."
P04-1083	J97-3002	o	Item Form: a32 a2 a49a51 a15 a52 a49 a51a16a33 Goal: a32a35a34 a49 a51 a15 a23a4a3 a12 a0a36a5 a24 a49 a51a37a33 Inference Rules Scan component d, a10a38a8 a7 a8 a0 : a39a41a40a43a42a44 a44a45 a23a25a24 a49 a5a47a46 a49 a2 a23a25a24 a5a49a48 a49 a51 a50 a23a25a24 a49 a5a47a46 a49 a20a43a5 a3a22 a23a25a24 a5a49a48 a49 a51 a51a14a52 a52 a53 a54a55 a55 a56 a23a25a24 a49 a5a47a46 a49 a2 a23a25a24 a5a49a48 a49 a51 a50 a23a25a24 a49 a5a47a46 a49a23 a19a57a24 a10a13a12 a19 a24 a23a25a24 a5a49a48 a49 a51 a58a59 a59 a60 Compose: a61a63a62a65a64 a66a68a67a69 a64 a66a71a70 a61a35a72a37a64 a66a68a67a73 a64 a66a71a70a36a74a76a75 a32a78a77 a64 a66a76a67a69 a64 a66a80a79a81a73 a64 a66 a14 a62a82a64 a66 a14 a72a37a64 a66 a33 a10 a77 a64 a66 a67a69 a64 a66a37a83 a73 a64 a66 a18 Figure 3: Logic C (C for CKY) These constraints are enforced by the d-span operators a84 and a85 . Parser C is conceptually simpler than the synchronous parsers of Wu (1997), Alshawi et al.
E09-1003	J93-2003	o	This approach is usually referred to as the noisy sourcechannel approach in SMT (Brown et al., 1993).
N07-1006	P02-1040	o	2 Three New Features for MT Evaluation Since our source-sentence constrained n-gram precision and discriminative unigram precision are both derived from the normal n-gram precision, it is worth describing the original n-gram precision metric, BLEU (Papineni et al. , 2002).
E09-1045	N07-1025	o	Thus, some research has been focused on deriving different word-sense groupings to overcome the finegrained distinctions of WN (Hearst and Schutze, 1993), (Peters et al., 1998), (Mihalcea and Moldovan, 2001), (Agirre and LopezDeLaCalle, 2003), (Navigli, 2006) and (Snow et al., 2007).
N03-1033	W02-1001	o	The Tagger Support cutoff Accuracy Collins (2002) 0 96.60% 5 96.72% Model 3W+TAGS variant 1 96.97% 5 96.93% Table 6: Effect of changing common word feature cutoffs (features with support  cutoff are excluded from the model).
D08-1066	P03-1021	o	The f are optimized by Minimum-Error Training (MERT) (Och, 2003).
W08-0301	N03-1017	o	4 Experiments 4.1 Experiment Settings A series of experiments were run to compare the performance of the three SWD models against the baseline, which is the standard phrase-based approach to SMT as elaborated in (Koehn et al., 2003).
C00-2109	P97-1003	o	There have been a lot of prol)OS~fls for statistical analysis, in ninny languages, in particular in English and Japanese (Magerman, 1995) (Sekine and Grishman, 1995) (Collins, 1997) (I/atnal)arkhi, 1997) (K.Shirai et.al, 1998) (Fujio and Matsnlnoto, 1998) (Itaruno ct.al, 1997)(Ehara, 1998).
D09-1132	W04-1013	o	(2004) use an information extraction engine to extract linguistic features from documents relevant to the target term.
W09-2807	A00-2024	o	Close to the problem studied here is Jing and McKeowns (Jing and McKeown, 2000) cut-and-paste method founded on EndresNiggemeyers observations.
P01-1027	J93-2003	o	This is exactly the standard lexicon probability a27a28a18a26a4 a20a12 a22 employed in the translation model described in (Brown et al. , 1993) and in Section 2.
P07-1089	P02-1040	o	Our evaluation metric is BLEU-4 (Papineni et al. , 2002), as calculated by the script mteval-v11b.pl with its default setting except that we used case-sensitive matching of n-grams.
D07-1070	P06-1027	o	We thus introduce a multiplier  to form the actual objective function that we minimize with respect to :4 summationdisplay iL logp,i(yi ) +  Nsummationdisplay inegationslashL H(p,i) (4) One may regard  as a Lagrange multiplier that is used to constrain the classifiers uncertainty H to be low, as presented in the work on entropy regularization (Brand, 1999; Grandvalet and Bengio, 2005; Jiao et al. , 2006).
J03-3002	P95-1026	o	This approach to minimally supervised classifier construction has been widely studied (Yarowsky 1995), especially in cases in which the features of interest are orthogonal in some sense (e.g. , Blum and Mitchell 1998; Abney 2002).
H05-1050	P95-1026	o	In the supervised condition, we used just 2 additional task instances, plant and tank, each with 4000 handannotated instances drawn from a large balanced corpus (Yarowsky, 1995).
P07-1123	P04-1035	p	First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al. , 2005; Kim and Hovy, 2006).
W08-1122	P06-1130	o	The generator used in our experiments is an instance of the second type, using a probability model defined over Lexical Functional Grammar c-structure and f-structure annotations (Cahill and van Genabith, 2006; Hogan et al., 2007).
D07-1006	P06-1097	o	We use the semi-supervised EMD algorithm (Fraser and Marcu, 2006b) to train the model.
W07-0716	N03-1017	o	1 Introduction Viewed at a very high level, statistical machine translationinvolvesfourphases: languageandtranslation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al. , 2003).
J05-4003	P02-1040	o	5 Translation performance was measured using the automatic BLEU evaluation metric (Papineni et al. 2002) on four reference translations.
W09-2205	N06-1020	o	Studies on self-training have focused mainly on generative, constituent based parsing (Steedman et al., 2003; McClosky et al., 2006; Reichart and Rappoport, 2007).
J07-3003	J93-1003	o	One could use the estimated co-occurrences from a small sample to compute the test statistics, most commonly Pearsons chi-squared test, the likelihood ratio test, Fishers exact test, cosine similarity, or resemblance (Jaccard coefficient) (Dunning 1993; Manning and Schutze 1999; Agresti 2002; Moore 2004).
E09-3006	P99-1048	o	In contrast, the latter computes four definite probabilities  which are included as features within a machine-learning classifier  from the Web in an attempt to overcome Bean and Riloffs (1999) data sparseness problem.
J93-2005	P90-1034	o	We have found, however, that collocational evidence can be employed to suggest which noun compounds reflect taxonomic relationships, using a strategy similar to that employed by Hindle (1990) for detecting synonyms.
I05-2027	W04-1013	o	In this paper, we compare the performance of this system, HybridTrim, with the Topiary system and a number of other baseline gisting systems on a collection of news documents from the DUC 2004 corpus (DUC, 2003).
N07-1014	J93-1003	o	 Significant neighbor-based co-occurrence: As discussed in (Dunning 1993), it is possible to measure the amount of surprise to see two neighboring words in a corpus at a certain frequency under the assumption of independence.
P08-1103	W02-1001	o	Perceptron Learning a discriminative structure prediction model with a perceptron update was first proposed by Collins (2002).
W07-1202	P04-1015	o	1 Introduction A recent development in data-driven parsing is the use of discriminative training methods (Riezler et al. , 2002; Taskar et al. , 2004; Collins and Roark, 2004; Turian and Melamed, 2006).
M98-1009	J93-2004	o	Training Data Our source for syntactically annotated training data was the Penn Treebank (Marcus et al. , 1993).
D09-1086	W06-3104	o	Ourmodelisthusa form of quasi-synchronous grammar (QG) (Smith and Eisner, 2006a).
J03-4003	P97-1003	o	Of particular relevance is other work on parsing the Penn WSJ Treebank (Jelinek et al. 1994; Magerman 1995; Eisner 1996a, 1996b; Collins 1996; Charniak 1997; Goodman 1997; Ratnaparkhi 1997; Chelba and Jelinek 1998; Roark 2001).
N04-2003	P95-1026	o	Two major research topics in this field are Named Entity Recognition (NER) (N. Wacholder and Choi, 1997; Cucerzan and Yarowsky, 1999) and Word Sense Disambiguation (WSD) (Yarowsky, 1995; Wilks and Stevenson, 1999).
A00-1031	J93-2004	o	The annotation consists of four parts: 1) a context-free structure augmented with traces to mark movement and discontinuous constituents, 2) phrasal categories that are annotated as node labels, 3) a small set of grammatical functions that are annotated as extensions to the node labels, and 4) part-of-speech tags (Marcus et al. , 1993).
P98-2148	J92-4003	o	To cope with this problem we 898 use the concept of class proposed for a word n-gram model (Brown et al. , 1992).
P08-1047	D07-1073	o	On the other hand, Kazama and Torisawa (2007) extracted hyponymy relations, which are independent of the NE categories, from Wikipedia and utilized it as a gazetteer.
W08-0306	P06-1096	o	9(Liang et al., 2006) report that, for translation reranking, such local updates (towards the oracle) outperform bold updates (towards the gold standard).
J02-1004	A92-1018	o	Our statistical tagging model is modified from the standard bigrams (Cutting et al. 1992) using Viterbi search plus onthe-fly extra computing of lexical probabilities for unknown morphemes.
W03-1025	P97-1003	o	Bikel and Chiang (2000) in fact contains two parsers: one is a lexicalized probabilistic contextfree grammar (PCFG) similar to (Collins, 1997); the other is based on statistical TAG (Chiang, 2000).
N07-1006	P02-1040	n	The most commonly used metric, BLEU, correlates well over large test sets with human judgments (Papineni et al. , 2002), but does not perform as well on sentence-level evaluation (Blatz et al. , 2003).
N06-1002	P03-1021	o	Word alignments were produced by GIZA++ (Och and Ney 2003) with a standard training regimen of five iterations of Model 1, five iterations of the HMM Model, and five iterations of Model 4, in both directions.
W07-2059	J96-1002	p	Exponential family models are a mainstay of modern statistical modeling (Brown, 1986) and they are widely and successfully used for example in text classification (Berger et al. , 1996).
D09-1079	P08-1058	o	Talbot and Brants (2008) used a Bloomier filter to encode a LM.
P06-1072	P97-1003	o	This was done for supervised parsing in different ways by Collins (1997), Klein and Manning (2003), and McDonald et al.
H05-1019	W04-1013	o	Our method is based on the Extended String Subsequence Kernel (ESK) (Hirao et al. , 2004b) which is a kind of convolution kernel (Collins and Duffy, 2001).
P06-1089	P95-1026	o	Yarowsky (1995) studied a method for word sense disambiguation using unlabeled data.
E99-1005	J93-1003	o	Proceedings of EACL '99 Determinants of Adjective-Noun Plausibility Maria Lapata and Scott McDonald and Frank Keller School of Cognitive Science Division of Informatics, University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW, UK {mlap, scottm, keller} @cogsci.ed.ac.uk Abstract This paper explores the determinants of adjective-noun plausibility by using correlation analysis to compare judgements elicited from human subjects with five corpus-based variables: co-occurrence frequency of the adjective-noun pair, noun frequency, conditional probability of the noun given the adjective, the log-likelihood ratio, and Resnik's (1993) selectional association measure.
W06-1668	W02-1002	o	4 Comparison to Related Work Previous work has compared generative and discriminative models having the same structure, such as the Naive Bayes and Logistic regression models (Ng and Jordan, 2002; Klein and Manning, 2002) and other models (Klein and Manning, 2002; Johnson, 2001).
D07-1031	N06-1041	o	Most previous work exploiting unsupervised training data for inferring POS tagging models has focused on semi-supervised methods in the in which the learner is provided with a lexicon specifying the possible tags for each word (Merialdo, 1994; Smith and Eisner, 2005; Goldwater and Griffiths, 2007) or a small number of prototypes for each POS (Haghighi and Klein, 2006).
N06-1025	N04-3012	o	We enrich the semantic information available to the classifier by using semantic similarity measures based on the WordNet taxonomy (Pedersen et al. , 2004).
D08-1066	N06-1033	o	(Zhang et al., 2006; Huang et al., 2008)), a binarizable segmentation/permutation can be recognized by a binarized Synchronous Context-Free Grammar (SCFG), i.e., an SCFG in which the right hand sides of all non-lexical rules constitute binarizable permutations.
C04-1140	W96-0213	o	Second, several tagging experiments on newspaper language, whether statistical (Ratnaparkhi, 1996; Brants, 2000) or rule-based (Brill, 1995), report that the tagging accuracy for unknown words is much lower than the overall accuracy.2 Thus, the lower percentage of unknown words in medical texts seems to be a sublanguage feature beneficial to POS taggers, whereas the higher proportion of unknown words in newspaper language seems to be a prominent source of tagging errors.
P98-1010	W95-0107	o	Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases (Ramshaw and Marcus, 1995; Vilain and Day, 1996).
W07-0710	P02-1040	p	1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al. , 2002) and errorbased optimization (Och, 2003).
W05-0804	J93-2003	o	Previous work from (Wang et al. , 1996) showed improvements in perplexity-oriented measures using mixture-based translation lexicon (Brown et al. , 1993).
C96-1038	J93-2004	o	4 Experiments The Penn Treebank (Marcus et al. , 1993) is used as the testing corpus.
W05-0826	N03-1017	o	See (Och and Ney, 2000), (Yamada and Knight, 2001), (Koehn and Knight, 2002), (Koehn et al. , 2003), (Schafer and Yarowsky, 2003) and (Gildea, 2003).
P98-2127	P90-1034	o	Ours is 772 similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed.
P09-1058	W96-0213	p	Their idea has proven effective for estimating the statistics of unknown words in previous studies (Ratnaparkhi, 1996; Nagata, 1999; Nakagawa, 2004).
P09-1103	C08-1138	o	Nevertheless, the generated rules are strictly required to be derived from the contiguous translational equivalences (Galley et al, 2006; Marcu et al, 2006; Zhang et al, 2007, 2008a, 2008b; Liu et al, 2006, 2007).
P09-1058	P08-1101	o	Table 8 compares the F1 results of our baseline model with Nakagawa and Uchimoto (2007) and Zhang and Clark (2008) on CTB 3.0.
W09-1804	J97-3002	o	4 Related Work (Zhang et al., 2003) and (Wu, 1997) tackle the problem of segmenting Chinese while aligning it to English.
W03-1101	J93-1003	o	NeATS computes the likelihood ratio  (Dunning, 1993) to identify key concepts in unigrams, bigrams, and trigrams, and clusters these concepts in order to identify major subtopics within the main topic.
D08-1006	P07-1010	o	More recently, however, Okanohara and Tsujii (2007) showed that a  1 Conditional maximum entropy models (Rosenfeld, 1996) provide somewhat of a counter-example, but there, too, many kinds of global and non-local features are difficult to use (Rosenfeld, 1997).
I08-1033	N03-1017	o	However for remedy, many of the current word alignment methods combine the results of both alignment directions, via intersection or 249 grow-diag-final heuristic, to improve the alignment reliability (Koehn et al., 2003; Liang et al., 2006; Ayan et al., 2006; DeNero et al., 2007).
C96-1020	J93-2004	o	Treebanks have been used within the field of natural language processing as a source of training data for statistical part og speech taggers (Black et al. , 1992; Brill, 1994; Merialdo, 1994; Weischedel et al. , 1993) and for statistical parsers (Black et al. , 1993; Brill, 1993; aelinek et al. , 1994; Magerman, 1995; Magerman and Marcus, 1991).
W09-2211	P06-1096	p	Perhaps more importantly, discriminative models have been shown to offer competitive performance on a variety of sequential and structured learning tasks in NLP that are traditionally tackled via generative models , such as letter-to-phoneme conversion (Jiampojamarn et al., 2008), semantic role labeling (Toutanova et al., 2005), syntactic parsing (Taskar et al., 2004), language modeling (Roark et al., 2004), and machine translation (Liang et al., 2006).
P08-1076	D07-1083	o	Following this idea, there have been introduced a parameter estimation approach for non-generative approaches that can effectively incorporate unlabeled data (Suzuki et al., 2007).
P03-1002	P97-1003	o	At last, the dependency parser presented in (Collins, 1997) is used to generate the full parse.
W05-0909	P02-1040	p	1 Introduction Automatic Metrics for machine translation (MT) evaluation have been receiving significant attention in the past two years, since IBM's BLEU metric was proposed and made available (Papineni et al 2002).
W03-1718	J96-1002	o	The training algorithm we used is the improved iterative scaling (IIS) described in (Berger et al, 1996)3.
P08-1054	W06-1643	o	Interestingly, the interannotator agreement on SWITCHBOARD (a0a2a1 a3a5a4a7a6a9a8a9a6 ) is higher than on the lecture corpus (0.372) and higher than the a0 -score reported by Galley (2006) for the ICSI meeting data used by Murray et al.
E09-1042	D07-1031	o	Similar to Goldwater and Griffiths (2007) and Johnson (2007), Toutanova and Johnson (2007) also use Bayesian inference for POS tagging.
P95-1033	J93-2003	o	1 Introduction Parallel corpora have been shown to provide an extremely rich source of constraints for statistical analysis (e.g. , Brown et al. 1990; Gale & Church 1991; Gale et al. 1992; Church 1993; Brown et al. 1993; Dagan et al. 1993; Dagan & Church 1994; Fung & Church 1994; Wu & Xia 1994; Fung & McKeown 1994).
P04-1047	P04-1041	o	The algorithm of (Cahill et al. , 2004b) translates the traces into corresponding re-entrancies in the f-structure representation (Figure 1).
E99-1018	A92-1018	o	On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al. , 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al. , 1996) or neural networks (Schmid, 1994).
J99-1003	J93-2003	o	For example, bilingual lexicographers can use bitexts to discover new cross-language lexicalization patterns (Catizone, Russell, and Warwick 1993; Gale and Church 1991b); students of foreign languages can use one half of a bitext to practice their reading skills, referring to the other half for translation when they get stuck (Nerbonne et al. 1997).
D07-1006	P06-1097	o	We then perform the D-step following (Fraser and A B C D d110d110d110d110d110 d110d110d110d110d110 d110d110d110d110 E d64d64d64 d64d64d64 d64 d126d126d126 d126d126d126 d126 A B C D d110d110d110d110d110 d110d110d110d110d110 d110d110d110d110 E d64d64d64 d64d64d64 d64 d126d126d126 d126d126d126 d126 Figure 2: Two alignments with the same translational correspondence Marcu, 2006b).
N06-1054	J93-2004	o	We use data from the CoNLL-2004 shared taskthe PropBank (Palmer et al. , 2005) annotations of the Penn Treebank (Marcus et al. , 1993), with sections 1518 as the training set and section 20 as the development set.
W08-0329	P07-1040	o	The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts (Rosti et al., 2007).
J07-4004	W96-0213	o	Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging (Ratnaparkhi 1996; Lafferty, McCallum, and Pereira 2001), named entity recognition (Borthwick 1999), chunking (Koeling 2000), and parsing (Johnson et al. 1999).
P08-1108	D07-1013	o	As expected, we see that MST does better than Malt for all categories except nouns and pronouns (McDonald and Nivre, 2007).
W07-0403	N03-1017	o	4.1 Translation Modeling We can test our models utility for translation by transforming its parameters into a phrase table for the phrasal decoder Pharaoh (Koehn et al. , 2003).
D09-1054	P08-1081	o	1 Introduction Recently, extracting questions, contexts and answers from post discussions of online forums incurs increasing academic attention (Cong et al., 2008; Ding et al., 2008).
C08-1024	P02-1053	o	Another line of research closely related to our work is the recognition of semantic orientation and sentiment analysis (Turney, 2002; Takamura et al., 2006; Kaji and Kitsuregawa, 2006).
W07-2072	P02-1053	o	2 Related work Our approach for emotion classification is based on the idea of (Hatzivassiloglou and McKeown, 1997) and is similar to those of (Turney, 2002) and (Turney and Littman, 2003).
P06-1123	J93-2004	o	3.3 Methods We parsed the English side of each bilingual bitext and both sides of each English/English bitext using an off-the-shelf syntactic parser (Bikel, 2004), which was trained on sections 02-21 of the Penn English Treebank (Marcus et al. , 1993).
H05-1057	J93-2003	o	There are five different IBM translation models (Brown et al. , 1993).
P04-1047	P04-1041	o	We are already using the extracted semantic forms in parsing new text with robust, wide-coverage PCFG-based LFG grammar approximations automatically acquired from the f-structure annotated Penn-II treebank (Cahill et al. , 2004a).
W99-0707	W95-0107	o	Chunking For NP chunking, \[Argamon et al. , 1998\] used data extracted from section 15-18 of the WS.J as a fixed train set and section 20 as a fixed test set, the same data as \[Ramshaw and Marcus, 1995\].
D07-1038	J93-2003	o	3.1 The traditional IBM alignment model IBM Model 4 (Brown et al. , 1993) learns a set of 4 probability tables to compute p(f|e) given a foreign sentence f and its target translation e via the following (greatly simplified) generative story: 361 NP-C NPB NPB NNP taiwan POS s NN surplus PP IN in NP-C NPB NN trade PP IN between NP-C NPB DT the CD two NNS shores FTD0 GR G4E7 DYBG EL DIDV TAIWAN IN TWO-SHORES TRADE MIDDLE SURPLUS R1: NP-C NPB x0:NPB x1:NN x2:PP x0 x2EL x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R2: NPB NNP taiwan POS s FTD0 R11: NPB x0:NNP POS s x0 R17: NPB NNP taiwan x0:POS x0 R12: NNP taiwan FTD0 R18: POS s FTD0 R3: PP x0:IN x1:NP-C x0 x1 R13: PP IN in x0:NP-C GR x0EL R19: PP IN in x0:NP-C x0 R4: IN in  GR R5: NP-C x0:NPB x1:PP  x1 x0 R5: NP-C x0:NPB x1:PP x1 x0 R20: NP-C x0:NPB PP x1:IN x2:NP-C x2 x0 x1 R6: PP IN between NP-C NPB DT the CD two NNS shores G4E7 R14: PP IN between x0:NP-C x0 R21: IN between EL R15: NP-C x0:NPB x0 R15: NP-C x0:NPB x0 R16: NPB DT the CD two NNS shores G4E7 R22: NPB x0:DT CD two x1:NNS x0 x1 R23: NNS shores G4E7 R24: DT the GR R7: NPB x0:NN x0 R7: NPB x0:NN x0 R7: NPB x0:NN x0 R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV Figure 2: A (English tree, Chinese string) pair and three different sets of multilevel tree-to-string rules that can explain it; the first set is obtained from bootstrap alignments, the second from this papers re-alignment procedure, and the third is a viable, if poor quality, alternative that is not learned.
W05-0404	J99-3003	o	This step can be seen as a multi-label, multi-class call classi cation problem for customer care applications (Gorin et al. , 1997; Chu-Carroll and Carpenter, 1999; Gupta et al. , To appear, among others).
P08-1076	D07-1083	o	As a solution, a given amount of labeled training data is divided into two distinct sets, i.e., 4/5 for estimating , and the 667 remaining 1/5 for estimating  (Suzuki et al., 2007).
C04-1140	J93-2004	o	This is most prominently evidenced by the PENN TREEBANK (Marcus et al. , 1993).
E06-1004	J93-2003	o	Increasingly, parallel corpora are becoming available for many language pairs and SMT systems have been built for French-English, German-English, Arabic-English, Chinese-English, Hindi-English and other language pairs (Brown et al. , 1993), (AlOnaizan et al. , 1999), (Udupa, 2004).
W97-0309	J92-4003	o	Though several algorithms (Brown et al. , 1992; Pereira, Tishby, and Lee, 1993) have been proposed 100( 9o( 80( 4O( 20( 1000 goo 80~ 41111 2@ 5 10 15 20 25 30 5 10 15 20 25 30 iteration of EM iteration of EM (a) (b) Figure 1: Plots of (a) training and (b) test perplexity versus number of iterations of the EM algorithm, for the aggregate Markov model with C = 32 classes.
D07-1015	D07-1014	o	For example, both papers propose minimum-risk decoding, and McDonald and Satta (2007) discuss unsupervised learning and language modeling, while Smith and Smith (2007) define hiddenvariable models based on spanning trees.
P07-1004	P02-1040	o	Evaluation Metrics We evaluated the generated translations using three different evaluation metrics: BLEU score (Papineni et al. , 2002), mWER (multi-reference word error rate), and mPER (multi-reference positionindependent word error rate) (Nieen et al. , 2000).
J02-4002	J93-1003	o	We measured associations using the log-likelihood measure (Dunning 1993) for each combination of target category and semantic class by converting each cell of the contingency into a 22 contingency table.
P06-1097	J93-2003	p	1 Introduction The most widely applied training procedure for statistical machine translation IBM model 4 (Brown et al. , 1993) unsupervised training followed by post-processing with symmetrization heuristics (Och and Ney, 2003) yields low quality word alignments.
P09-1087	P08-1066	n	This provides a compelling advantage over previous dependency language models for MT (Shen et al., 2008),whichusea5-gramLMonlyduringreranking.
W07-1202	W02-1001	o	One popular approach is to use a log-linear parsing model and maximise the conditional likelihood function (Johnson et al. , 1999; Riezler et al. , 2002; Clark and Curran, 2004b; Malouf and van Noord, 2004; Miyao and Tsujii, 2005).
D09-1008	C08-1041	o	A remedy is to aggressively limit the feature space, e.g. to syntactic labels or a small fraction of the bi-lingual features available, as in (Chiang et al., 2008; Chiang et al., 2009), but that reduces the benefit of lexical features.
D09-1111	P03-1021	o	Note that generative hybrids are the norm in SMT, where translation scores are provided by a discriminative combination of generative models (Och, 2003).
A94-1012	J93-2003	o	The computation mechanism of GP and LP bears a resemblance to the EM algorithm(Dempster et al. , 1977; Brown et al. , 1993), which iteratively computes maximum likelihood estimates from incomplete data.
P08-1077	N03-1003	o	(2004) and Barzilay and Lee (2003) used comparable news articles to obtain sentence level paraphrases.
P07-1096	J96-1002	o	766 System Beam Error% (Ratnaparkhi, 1996) 5 3.37 (Tsuruoka and Tsujii, 2005) 1 2.90 (Collins, 2002) 2.89 Guided Learning, feature B 3 2.85 (Tsuruoka and Tsujii, 2005) all 2.85 (Gimenez and M`arquez, 2004) 2.84 (Toutanova et al. , 2003) 2.76 Guided Learning, feature E 1 2.73 Guided Learning, feature E 3 2.67 Table 4: Comparison with the previous works According to the experiments shown above, we build our best system by using feature set E with beam width B = 3.
D07-1033	P04-1015	o	Recently, severalmethods(Collins and Roark, 2004; Daume III and Marcu, 2005; McDonald and Pereira, 2006) have been proposed with similar motivation to ours.
P00-1015	W95-0107	o	This second expression is similar to that used in [Marcus 1995].
W09-0404	W05-0909	o	However, there is little agreement on what types of knowledge are helpful: Some suggestions concentrate on lexical information, e.g., by the integration of word similarity information as in Meteor (Banerjee and Lavie, 2005) or MaxSim (Chan and Ng, 2008).
W07-1033	J96-1002	o	is the previous BIO tag, S is the target sentence, and fj and lj are feature functions and parameters of a log-linear model (Berger et al. , 1996).
H05-1099	W02-1001	o	task, originally introduced in Ramshaw and Marcus (1995) and also described in (Collins, 2002; Sha and Pereira, 2003), brackets just base NP constituents5.
P07-1092	J93-2003	o	1 Introduction Statistical machine translation (Brown et al. , 1993) has seen many improvements in recent years, most notably the transition from wordto phrase-based models (Koehn et al. , 2003).
H05-1024	N03-1017	p	For our experiments, we chose GIZA++ (Och and Ney, 2000) and the RA approach (Koehn et al. , 2003) the best known alignment combination technique as our initial aligners.1 4.2 TBL Templates Our templates consider consecutive words (of size 1, 2 or 3) in both languages.
I08-2116	H05-1087	o	2 F 1 -score Maximization Training of LRM We first review the F 1 -score maximization training method for linear models using a logistic function described in (Jansche, 2005).
P99-1029	J90-1003	o	The mutual information Ml(x,y) is defined as the following formula (Church and Hanks, 1990).
P03-1055	J96-1002	o	The other main difference is the apparently nonlocal nature of the problem, which motivates our choice of a Maximum Entropy (ME) model for the tagging task (Berger et al. , 1996).
D08-1051	P02-1040	o	To this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) propose the use of the so-called log-linear models, where the decision rule is given by the expression y = argmax y Msummationdisplay m=1 mhm(x,y) (3) where hm(x,y) is a score function representing an important feature for the translation of x into y, M is the number of models (or features) and m are the weights of the log-linear combination.
J01-3001	P95-1026	o	Currently, machine learning methods (Yarowsky 1995; Rigau, Atserias, and Agirre 1997) and combinations of classifiers (McRoy 1992) have been popular.
D08-1084	J93-2003	o	Although we have argued (section 2) that this is unlikely to succeed, to our knowledge, we are the first to investigate the matter empirically.11 The best-known MT aligner is undoubtedly GIZA++ (Och and Ney, 2003), which contains implementations of various IBM models (Brown et al., 1993), as well as the HMM model of Vogel et al.
W09-0436	N03-1017	p	4 Machine Translation Experiments 4.1 Experimental Setting For our MT experiments, we used a reimplementation of Moses (Koehn et al., 2003), a state-of-the-art phrase-based system.
I08-2093	N06-1041	o	The recent work of (Haghighi and Klein, 2006) and (Quirk et al., 2005) were also sources of inspiration.
D09-1123	P08-1066	n	Thirdly, (Shen et al., 2008) deploys the dependency language model to augment the lexical language model probability be1183 tween two head words but never seek a full dependency graph.
I08-1033	J93-2003	o	Most existing methods treat word tokens as basic alignment units (Brown et al., 1993; Vogel et al., 1996; Deng and Byrne, 2005), however, many languages have no explicit word boundary markers, such as Chinese and Japanese.
C92-2082	P90-1034	o	There bas recently been work in the detection of semantically related nouns via, for example, shared argument structures (Hindle 1990), and shared dictionary definition context (Wilks e al. 1990).
W00-1201	P97-1003	o	"2.1 Model 2 of (Collins, 1997) Both parsing models discussed in this paper inherit a great deal from this model, so we briefly describe its ""progenitive"" features here, describing only how each of the two models of this paper differ in the subsequent two sections."
P09-2066	W04-1013	o	For a comparison, we also include the ROUGE-1 Fscores (Lin, 2004) of each system output against the human compressed sentences.
W05-0833	P02-1040	o	In order to create the necessary SMT language and translation models, they used:  Giza++ (Och & Ney, 2003);2  the CMU-Cambridge statistical toolkit;3  the ISI ReWrite Decoder.4 Translation was performed from EnglishFrench and FrenchEnglish, and the resulting translations were evaluated using a range of automatic metrics: BLEU (Papineni et al. , 2002), Precision and Recall 2 3 4 185 (Turian et al. , 2003), and Wordand Sentence Error Rates.
D08-1036	D07-1031	o	Monte Carlo sampling methods and Variational Bayes are two kinds of approximate inference methods that have been applied to Bayesian inference of unsupervised HMM POS taggers (Goldwater and Griffiths, 2007; Johnson, 2007).
W09-1505	D07-1090	o	We have also used TPTs to encode n-gram count databases such as the Google 1T web n-gram database (Brants and Franz, 2006), but are not able to provide detailed results within the space limitations of this paper.4 5.1 Perplexity computation with 5-gram language models We compared the performance of TPT-encoded language models against three other language model implementations: the SRI language modeling toolkit (Stolcke, 2002), IRSTLM (Federico and Cettolo, 2007), and the language model implementation currently used in the Portage SMT system (Badr et al., 2007), which uses a pointer-based implementation but is able to perform fast LM filtering at load time.
W07-1429	N03-1003	n	Table 2: Figures about clustering algorithms Algorithm # Sentences/# Clusters S-HAC 6,23 C-HAC 2,17 QT 2,32 EM 4,16 In fact, table 2 shows that most of the clusters have less than 6 sentences which leads to question the results presented by (Barzilay & Lee, 2003) who only keep the clusters that contain more than 10 sentences.
E99-1023	W95-0107	p	(Ramshaw and Marcus, 1995) shows that baseNP recognition (Fz=I =92.0) is easier than finding both NP and VP chunks (Fz=1=88.1) and that increasing the size of the training data increases the performance on the test set.
I05-2027	W04-1013	o	Since the DUC 2004 evaluation, Lin (2004) has concluded that certain ROUGE metrics correlate better with human judgments than others, depending on the summarisation task being evaluated, i.e. single document, headline, or multi-document summarisation.
P04-1015	W02-1001	o	2.1 Linear Models for NLP We follow the framework outlined in Collins (2002; 2004).
D07-1099	P07-1080	p	3 Parsing Exact inference in ISBN models is not tractable, but effective approximations were proposed in (Titov and Henderson, 2007a).
H05-1049	P02-1040	o	3 Semantic Representation 3.1 The Need for Dependencies Perhaps the most common representation of text for assessing content is Bag-Of-Words or Bag-of-NGrams (Papineni et al. , 2002).
D09-1040	P03-1021	o	Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function.
E06-1007	J96-2004	o	We then examined the inter-annotator reliability of the annotation by calculating the  score (Carletta, 1996).
P07-2013	N04-3012	o	The implementation includes path-length (Rada et al. , 1989; Wu & Palmer, 1994; Leacock & Chodorow, 1998), information-content (Resnik, 1995; Seco et al. , 2004) and text-overlap (Lesk, 1986; Banerjee & Pedersen, 2003) measures, as described in Strube & Ponzetto (2006).
H05-1098	P02-1040	o	5 Analysis Over the last few years, several automatic metrics for machine translation evaluation have been introduced, largely to reduce the human cost of iterative system evaluation during the development cycle (Lin and Och, 2004; Melamed et al. , 2003; Papineni et al. , 2002).
P03-1064	W95-0107	o	(Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL).
D07-1025	W02-1001	o	2.2 A Perceptron-Based Edit Model In this section we present a general-purpose extension of perceptron training for sequence labeling, due to Collins (2002), to the problem of sequence alignment.
D08-1088	P03-1021	o	This operation can be used in applications like Minimum Error Rate Training (Och, 2003), or optimizing system combination as described by Hillard et al.
I08-1030	P03-1021	o	In the training phase, bilingual parallel sentences are preprocessed and aligned using alignment algorithms or tools such as GIZA++ (Och and Ney, 2003).
W01-1208	J93-2003	o	P(d)  P L (d) (4) Statistical approaches to language modeling have been used in much NLP research, such as machine translation (Brown et al. , 1993) and speech recognition (Bahl et al. , 1983).
P98-1065	J90-1003	o	The collocations have been calculated according to the method described in Church and Hanks (1990) by moving a window on the texts.
J07-2003	P03-1021	o	The rules extracted from the training bitext have the following features: a114 P( | )andP( | ), the latter of which is not found in the noisy-channel model, but has been previously found to be a helpful feature (Och and Ney 2002); 210 Chiang Hierarchical Phrase-Based Translation a114 the lexical weights P w ( | )andP w ( | ), which estimate how well the words in  translate the words in  (Koehn, Och, and Marcu 2003); 4 a114 a penalty exp(1) for extracted rules, analogous to Koehns phrase penalty (Koehn 2003), which allows the model to learn a preference for longer or shorter derivations.
W07-1707	J96-2004	o	Obtained percent agreement of 0.988 and  coefficient (Carletta, 1996) of 0.975 suggest high convergence of both annotations.
E99-1023	W95-0107	o	We have used the optimal experiment configurations that we had obtained from the fourth experiment series for processing the complete (Ramshaw and Marcus, 1995) data set.
P08-1009	P03-1021	o	Candidate translations are scored by a linear combination of models, weighted according to Minimum Error Rate Training or MERT (Och, 2003).
P08-1058	D07-1090	p	Here we choose to work with stupid backoff smoothing (Brants et al., 2007) since this is significantly more efficient to train and deploy in a distributed framework than a contextdependent smoothing scheme such as Kneser-Ney.
P07-2046	N03-1017	o	It is an extension of Pharaoh (Koehn et al. , 2003), and supports factor training and decoding.
H05-1034	W02-1001	o	The four models we compare are a maximum a posteriori (MAP) method and three discriminative training methods, namely the boosting algorithm (Collins, 2000), the average perceptron (Collins, 2002) and the minimum sample risk method (Gao et al. , 2005).
D07-1097	D07-1013	o	As shown by McDonald and Nivre (2007), the Single Malt parser tends to suffer from two problems: error propagation due to the deterministic parsing strategy, typicallyaffectinglongdependenciesmorethan short ones, and low precision on dependencies originating in the artificial root node due to fragmented parses.9 The question is which of these problems is alleviatedbythemultipleviewsgivenbythecomponent parsers in the Blended system.
P05-1039	J93-2004	o	It is available in several formats, and in this paper, we use the Penn Treebank (Marcus et al. , 1993) format of NEGRA.
W07-2058	P05-1045	o	We extract the named entities from the web pages using the Stanford Named Entity Recognizer (Finkel et al. , 2005).
J07-2003	P03-1021	o	Phrases of up to 10 in length on the French side were extracted from the parallel text, and minimum-error-rate training (Och 2003) was 8 We can train on the full training data shown if tighter constraints are placed on rule extraction for the United Nations data.
D09-1105	W02-1001	o	We used the averaged perceptron algorithm (Freund and Schapire, 1998; Collins, 2002) to train the parameters of the model.
P07-1040	P03-1021	o	In (Matusov et al. , 2006), different word orderings are taken into account by training alignment models by considering all hypothesis pairs as a parallel corpus using GIZA++ (Och and Ney, 2003).
D08-1060	P03-1021	o	We use MER (Och, 2003) to tune the decoders parameters using a development data set.
D09-1156	P06-1101	o	Although some early systems for web-page analysis induce rules at character-level (e.g., such as WIEN (Kushmerick et al., 1997) and DIPRE (Brin, 1998)), most recent approaches for set expansion have used either tokenized and/or parsed free-text (Carlson et al., 2009; Talukdar et al., 2006; Snow et al., 2006; Pantel and Pennacchiotti, 2006), or have incorporated heuristics for exploiting HTML structures that are likely to encode lists and tables (Nadeau et al., 2006; Etzioni et al., 2005).
P09-1056	D07-1031	p	Recent projects in semisupervised (Toutanova and Johnson, 2007) and unsupervised (Biemann et al., 2007; Smith and Eisner, 2005) tagging also show significant progress.
D07-1006	P06-1097	p	We compare semisupervised LEAF with a previous state of the art semi-supervised system (Fraser and Marcu, 2006b).
P07-1034	W06-1615	o	Following (Blitzer et al. , 2006), we call the first the source domain, and the second the target domain.
W08-0304	P03-1021	o	The first, Powells method, was advocated by Och (2003) when MERT was first introduced for statistical machine translation.
N03-1032	J90-1003	o	The window size may vary, Church and Hanks (1990) used windows of size 2 and 5.
P99-1051	J90-1003	o	We preferred the log-likelihood ratio to other statistical scores, such as the association ratio (Church and Hanks, 1990) or ;(2, since it adequately takes into account the frequency of the co-occurring words and is less sensitive to rare events and corpussize (Dunning, 1993; Daille, 1996).
P98-1034	W95-0107	o	More recently, Ramshaw & Marcus (In press) apply transformation-based learning (Brill, 1995) to the problem.
P05-1059	J97-3002	o	Wu (1997) demonstrated that for pairs of sentences that are less than 16 words, the ITG alignment space has a good coverage over all possibilities.
N09-1003	D07-1061	o	Method Source Spearman (Strube and Ponzetto, 2006) Wikipedia 0.190.48 (Jarmasz, 2003) WordNet 0.330.35 (Jarmasz, 2003) Rogets 0.55 (Hughes and Ramage, 2007) WordNet 0.55 (Finkelstein et al., 2002) Web corpus, WN 0.56 (Gabrilovich and Markovitch, 2007) ODP 0.65 (Gabrilovich and Markovitch, 2007) Wikipedia 0.75 SVM Web corpus, WN 0.78 Table 9: Comparison with previous work for WordSim353.
D07-1038	P06-1097	o	If human-aligned data is available, the EMD algorithm provides higher baseline alignments than GIZA++ that have led to better MT performance (Fraser and Marcu, 2006).
P08-1024	N03-1017	o	The standard solution is to approximate the maximum probability translation using a single derivation (Koehn et al., 2003).
J07-3004	J93-2004	p	One of the largest and earliest such efforts is the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993; Marcus et al. 1994), which contains a one-million word  Institute for Research in Cognitive Science, University of Pennsylvania, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104-6228, USA.
N07-1016	P06-1101	o	Second, we follow Snow et al.s work (2006) on taxonomy induction in incorporating transitive closure constraints in our probability calculations, as explained below.
H05-1099	W95-0107	o	1 Introduction Finite-state parsing (also called chunking or shallow parsing) has typically been motivated as a fast firstpass for  or approximation to  more expensive context-free parsing (Abney, 1991; Ramshaw and Marcus, 1995; Abney, 1996).
C04-1030	P03-1021	o	Alternatively, one can train them with respect to the final translation quality measured by some error criterion (Och, 2003).
W99-0610	J93-1007	o	~F ~c ~R ~cR (2) ~\]~) continue explanations, we begin by mentioning the 'Xtrgct' tool by Smadja (Smadja, 1993).
D07-1049	D07-1091	o	Decoding is carried-out using the Moses decoder (Koehn and Hoang, 2007).
P09-1054	W96-0213	o	The applications range from simple classification tasks such as text classification and history-based tagging (Ratnaparkhi, 1996) to more complex structured prediction tasks such as partof-speech (POS) tagging (Lafferty et al., 2001), syntactic parsing (Clark and Curran, 2004) and semantic role labeling (Toutanova et al., 2005).
D09-1043	W02-1001	o	1 Introduction In this paper, we show how discriminative training with averaged perceptron models (Collins, 2002) can be used to substantially improve surface realization with Combinatory Categorial Grammar (Steedman, 2000, CCG).
D09-1127	J97-3002	o	Joint parsing with a simplest synchronous context-free grammar (Wu, 1997) is O(n6) as opposed to the monolingual O(n3) time.
W06-3107	J93-2003	p	Statistical models for machine translation heavily depend on the concept of alignment, specifically, the well known IBM word based models (Brown et al. , 1993).
J00-2004	J93-2003	o	Evaluation 6.1 Evaluation at the Token Level This section compares translation model estimation methods A, B, and C to each other and to Brown et al.'s (1993b) Model 1.
N04-1022	P03-1021	o	For all performance metrics, we show the 70% confidence interval with respect to the MAP baseline computed using bootstrap resampling (Press et al. , 2002; Och, 2003).
D07-1031	N06-1041	o	It is difficult to compare these with previous work, but Haghighi and Klein (2006) report that in a completely unsupervised setting, their MRF model, which uses a large set of additional features and a more complex estimation procedure, achieves an average 1-to-1 accuracy of 41.3%.
P05-1077	P90-1034	o	4 Building Noun Similarity Lists A lot of work has been done in the NLP community on clustering words according to their meaning in text (Hindle, 1990; Lin, 1998).
P08-1108	D07-1013	o	First, the graph-based models have better precision than the transition-based models when predicting long arcs, which is compatible with the results of McDonald and Nivre (2007).
W08-0301	W05-0909	o	It is dubious whether SWD is useful regarding recall-oriented metrics like METEOR (Banerjee and Lavie, 2005), since SWD removes information in source sentences.
W08-0401	P02-1040	o	4 5 Experiments 5.1 Evaluation Measures We evaluated the proposed method using four evaluation measures, BLEU (Papineni et al., 2002), NIST (Doddington 2002), WER(word error rate), and PER(position independent word error rate).
W06-3119	N03-1017	o	5 Results We present results that compare our system against the baseline Pharaoh implementation (Koehn et al. , 2003a) and MER training scripts provided for this workshop.
P08-1076	D07-1083	n	Surprisingly, although JESS-CM is a simpler version of the hybrid model in terms of model structure and parameter estimation procedure, JESS-CM provides F-scores of 94.45 and 88.03 for CoNLL00 and 03 data, respectively, which are 0.15 and 0.83 points higher than those reported in (Suzuki et al., 2007) for the same configurations.
C96-1067	J93-2003	o	IIowever, (Dagan et al. , 1993) have shown that knowledge of target-text length is not crucial to the model's i)ertbrmanee.
D09-1079	D07-1090	o	All the TB-LMs and O-RLMs were unpruned 5gram models and used Stupid-backoff smoothing (Brants et al., 2007) 2 with the backoff parameter set to 0.4 as suggested.
H05-1011	W02-1001	o	4 Parameter Optimization We optimize the feature weights using a modified version of averaged perceptron learning as described by Collins (2002).
C08-1086	C98-2122	o	Following Lin (1998), we use syntactic dependencies between words to model their semantic properties.
D07-1007	P02-1040	p	In addition to the widely used BLEU (Papineni et al. , 2002) and NIST (Doddington, 2002) scores, we also evaluate translation quality with the recently proposed Meteor (Banerjee and Lavie, 2005) and four edit-distance style metrics, Word Error Rate (WER), Positionindependent word Error Rate (PER) (Tillmann et al. , 1997), CDER, which allows block reordering (Leusch et al. , 2006), and Translation Edit Rate (TER) (Snover et al. , 2006).
D08-1059	W02-1001	o	We use the discriminative perceptron learning algorithm (Collins, 2002; McDonald et al., 2005) to train the values of vectorw.
D09-1161	W02-1001	n	Our study also shows that the simulated-annealing algorithm (Kirkpatrick et al. 1983) is more effective 1552 than the perceptron algorithm (Collins 2002) for feature weight tuning.
D09-1111	N03-1017	o	Substring-based transliteration with a generative hybrid model is very similar to existing solutions for phrasal SMT (Koehn et al., 2003), operating on characters rather than words.
J05-3002	A00-2024	o	While earlier approaches for text compression were based on symbolic reduction rules (Grefenstette 1998; Mani, Gates, and Bloedorn 1999), more recent approaches use an aligned corpus of documents and their human written summaries to determine which constituents can be reduced (Knight and Marcu 2002; Jing and McKeown 2000; Reizler et al. 2003).
W08-2006	D07-1061	o	We further note that our results are different from that of (Hughes and Ramage, 2007) as they use extensive feature engineering and weight tuning during the graph generation process that we have not been able to reproduce.
W01-1405	J93-2003	o	Models describing these types of dependencies are referred to as alignment mappings (Brown et al. 1993): alignment mapping: j ! i = aj ; which assigns a source word fj in position j to a target word ei in position i = aj.
W05-0835	J93-2003	o	Most of them rely on the concept of alignment: a mapping from words or groups of words in a sentence into words or groups in the other (in the case of (Vidal et al. , 1993) the mapping goes from rules in a grammar for a language into rules of a grammar for the other language).
C96-1097	J90-1003	o	There are many method proposed to extract rigid expressions from corpora such as a method of focusing on the binding strength of two words (Church and Hanks 1990); the distance between words (Smadja and Makeown 1990); and the number of combined words and frequency of appearance (Kita 1993, 1994).
P97-1009	J93-1003	o	"64 Table 1: Subjects of ""employ"" with highest likelihood ratio word freq logA word freq logA bRG 64 50.4 plant 14 31.0 company 27 28.6 operation 8 23.0 industry 9 14.6 firm 8 13.5 pirate 2 12.1 unit 9 9.32 shift 3 8.48 postal service 2 7.73 machine 3 6.56 corporation 3 6.47 manufacturer 3 6.21 insurance company 2 6.06 aerospace 2 5.81 memory device 1 5.79 department 3 5.55 foreign office 1 5.41 enterprise 2 5.39 pilot 2 5.37 *ORG includes all proper names recognized as organizations The logA column are their likelihood ratios (Dunning, 1993)."
C08-1027	N03-1017	p	1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003) has been one of the major developments in statistical approaches to translation.
N09-1068	P07-1033	o	Recall that the log likelihood of our model is:  d parenleftBigg Lorig(Dd;d) i (d,i ,i)2 2 2d parenrightBigg  i (,i)2 2 2 We now introduce a new variable d = d , and plug it into the equation for log likelihood:  d parenleftBigg Lorig(Dd;d +) i (d,i)2 2 2d parenrightBigg  i (,i)2 2 2 The result is the model of (Daume III, 2007), where the d are the domain-specific feature weights, and d are the domain-independent feature weights.
N03-2016	P02-1040	o	For the evaluation of translation quality, we used the BLEU metric (Papineni et al. , 2002), which measures the n-gram overlap between the translated output and one or more reference translations.
D07-1070	P06-1027	o	In particular, Abney defines a function K that is an upper bound on the negative log-likelihood, and shows his bootstrapping algorithms locally minimize K. We now present a generalization of Abneys K function and relate it to another semi-supervised learning technique, entropy regularization (Brand, 1999; Grandvalet and Bengio, 2005; Jiao et al. , 2006).
J04-2003	J93-2003	o	The translation models they presented in various papers between 1988 and 1993 (Brown et al. 1988; Brown et al. 1990; Brown, Della Pietra, Della Pietra, and Mercer 1993) are commonly referred to as IBM models 15, based on the numbering in Brown, Della Pietra, Della Pietra, and Mercer (1993).
W06-1649	P95-1026	o	The information for semi-supervised sense disambiguation is usually obtained from bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages) (Brown et al. , 1991; Dagan and Itai, 1994), or sense-tagged seed examples (Yarowsky, 1995).
P08-1108	D07-1013	o	Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased (McDonald and Nivre, 2007).
W02-2001	J93-1003	o	One aspect of VPCs that makes them dicult to extract (cited in, e.g., Smadja (1993)) is that the verb and particle can be non-contiguous, e.g. hand the paper in and battle right on.
P09-1059	P07-1033	o	This method is very similar to some ideas in domain adaptation (Daume III and Marcu, 2006; Daume III, 2007), but we argue that the underlying problems are quite different.
N09-1055	N07-1039	p	With the in-depth study of opinion mining, researchers committed their efforts for more accurate results: the research of sentiment summarization (Philip et al., 2004; Hu et al., KDD 2004), domain transfer problem of the sentiment analysis (Kanayama et al., 2006; Tan et al., 2007; Blitzer et al., 2007; Tan et al., 2008; Andreevskaia et al., 2008; Tan et al., 2009) and finegrained opinion mining (Hatzivassiloglou et al., 2000; Takamura et al., 2007; Bloom et al., 2007; Wang et al., 2008; Titov et al., 2008) are the main branches of the research of opinion mining.
J07-3002	P03-1021	o	The output of GIZA++ is then post-processed using the three symmetrization heuristics described in Och and Ney (2003).
J05-4005	W02-1001	o	The key difference is that, instead of using the delta rule of Equation (8) (as shown in line 5 of Figure 4), Collins (2002) updates parameters using the rule:  t+1 d   t d + f d (w R i )  f d (w i ).
N06-3005	W02-1011	o	So far research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al. , 2004; Riloff et al. , 2003; Riloff and Wiebe, 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al. , 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Pang et al. , 2002; Dave et al. , 2003; Nasukawa and Yi, 2003; Morinaga et al. , 2002).
W03-1702	P95-1026	o	Yarowsky (1995) showed that the learning strategy of bootstrapping from small tagged data led to results rivaling supervised training methods.
P08-1099	N06-1041	o	(2005) and compare with results reported by HK06 (Haghighi and Klein, 2006) and CRR07 (Chang et al., 2007).
P08-1003	P06-1101	o	4 Related Work 4.1 Acquisition of Classes of Instances Although some researchers focus on re-organizing or extending classes of instances already available explicitly within manually-built resources such as Wikipedia (Ponzetto and Strube, 2007) or WordNet (Snow et al., 2006) or both (Suchanek et al., 2007), a large body of previous work focuses on compiling sets of instances, not necessarily labeled, from unstructured text.
W01-1410	J93-2003	o	"We based our design on the IBM models 1 and 2 (Brown et al. , 1993), but taking into account that our model must generate correct derivations in a given grammar, not any seBEGIN some END<animals> eat <animals> (a) ""some a88 animalsa89 eat a88 animalsa89 "" BEGIN some END<animals> eat are <animals> dangerous (b) ""some a88 animalsa89 are dangerous"" BEGIN <animals> some END eat are <animals> dangerous (c) ""a88 animalsa89 are dangerous"" BEGIN snakes rats people some END eat are snakes rats people dangerous (d) Expansion of a88 animalsa89 Figure 3: Using a category a86 animalsa87 for ""snakes"", ""rats"" and ""people"" in the example of Figure 1."
D09-1023	P08-1066	p	There is also substantial work in the use of target-side syntax (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008).
E99-1023	W95-0107	o	The chunking classification was made by (Ramshaw and Marcus, 1995) based on the parsing information in the WSJ corpus.
C04-1006	J93-2003	p	6 Related Work The popular IBM models for statistical machine translation are described in (Brown et al. , 1993).
N06-1001	N04-1035	o	To this end, the translational correspondence is described within a translation rule, i.e., (Galley et al. , 2004) (or a synchronous production), rather than a translational phrase pair; and the training data will be derivation forests, instead of the phrase-aligned bilingual corpus.
W02-1405	J93-2003	o	2 Our statistical engine 2.1 The statistical models In this study, we built an SMT engine designed to translate from French to English, following the noisy-channel paradigm flrst described by (Brown et al. , 1993b).
P06-1087	W95-0107	p	4.2 Support Vector Machines We chose to adopt a tagging perspective for the Simple NP chunking task, in which each word is to be tagged as either B, I or O depending on wether it is in the Beginning, Inside, or Outside of the given chunk, an approach first taken by Ramshaw and Marcus (1995), and which has become the de-facto standard for this task.
C00-2124	W95-0107	o	The data was seglnente.d into baseNP parts and non-lmseNP t)arts ill a similar fitshion as the data used 1)y Ramshaw and Marcus (1995).
D09-1158	P07-1033	o	Daume III (Daume III, 2007) divided features into three classes: domainindependent features, source-domain features and target-domain features.
J06-1005	J93-1003	o	5 The SemCor collection (Miller et al., 1993) is a subset of the Brown Corpus and consists of 352 news articles distributed into three sets in which the nouns, verbs, adverbs, and adjectives have been manually tagged with their corresponding WordNet senses and part-of-speech tags using Brills tagger (1995).
W07-1202	W96-0213	o	It uses a log-linear model to define a distribution over the lexical category set for each word and the previous two categories (Ratnaparkhi, 1996) and the forward backward algorithm efficiently sums over all histories to give a distibution for each word.
W05-0817	J93-2003	p	A quite different approach from our hypotheses testing implemented in the TREQ-AL aligner is taken by the model-estimating aligners, most of them relying on the IBM models (1 to 5) described in the (Brown et al. 1993) seminal paper.
P09-1104	P07-1003	o	We also trained an HMM aligner as described in DeNero and Klein (2007) and used the posteriors of this model as features.
W05-0834	P03-1021	o	More details on these standard criteria can be found for instance in (Och, 2003).
W03-0407	P95-1026	o	1 Introduction Co-training (Blum and Mitchell, 1998), and several variants of co-training, have been applied to a number of NLP problems, including word sense disambiguation (Yarowsky, 1995), named entity recognition (Collins and Singer, 1999), noun phrase bracketing (Pierce and Cardie, 2001) and statistical parsing (Sarkar, 2001; Steedman et al. , 2003).
W03-0304	J93-2003	o	Yet, the very nature of these alignments, as defined in the IBM modeling approach (Brown et al. , 1993), lead to descriptions of the correspondences between sourcelanguage (SL) and target-language (TL) words of a translation that are often unsatisfactory, at least from a human perspective.
W02-1011	J96-1002	o	However, feature/class functions are traditionally deflned as binary (Berger et al. , 1996); hence, explicitly incorporating frequencies would require difierent functions for each count (or count bin), making training impractical.
C08-1111	P02-1053	o	(2007) apply the theory of (Hatzivassiloglou and McKeown, 1997) and (Turney, 2002) to emotion classification and propose a method based on the co-occurrence distribution over content words and six emotion words (e.g. joy, fear).
P05-2024	J96-1002	o	We employ loglinear models (Berger et al. , 1996) for the disambiguation.
P06-1028	W95-0107	o	These tasks are generally treated as sequential labeling problems incorporating the IOB tagging scheme (Ramshaw and Marcus, 1995).
W07-2072	P02-1053	o	Some of the differences between our approach and those of Turney (2002) are mentioned below: ??objectives: Turney (2002) aims at binary text classification, while our objective is six class classification of one-liner headlines.
W02-0207	J96-2004	o	5 Reliability of Annotations 5.1 The Kappa Statistic To measure the reliability of annotations we used the Kappa statistic (Carletta, 1996).
W06-3122	P02-1040	o	Although Phramer provides decoding functionality equivalent to Pharaohs, we preferred to use Pharaoh for this task because it is much faster than Phramer  between 2 and 15 times faster, depending on the configuration  and preliminary tests showed that there is no noticeable difference between the output of these two in terms of BLEU (Papineni et al. , 2002) score.
P03-1012	J93-2003	o	1 Introduction Word alignments were first introduced as an intermediate result of statistical machine translation systems (Brown et al. , 1993).
W03-0401	P97-1003	o	Since an existing study incorporates these relations ad hoc (Collins, 1997), they are apparently crucial in accurate disambiguation.
D07-1009	W02-1001	o	Our hierarchical training method yields significant improvement when compared to a similar nonhierarchical model which instead uses the standard 2Data and code used in this paper are available at  perceptron update of Collins (2002).
W06-3109	J93-2003	p	The most widely used single-word-based statistical alignment models (SAMs) have been proposed in (Brown et al. , 1993; Ney et al. , 2000).
D09-1134	P95-1026	o	This process is repeated for a number of iterations in a self-training fashion (Yarowsky, 1995).
H05-1098	N03-1017	o	The need for some way to model aspects of syntactic behavior, such as the tendency of constituents to move together as a unit, is widely recognizedthe role of syntactic units is well attested in recent systematic studies of translation (Fox, 2002; Hwa et al. , 2002; Koehn and Knight, 2003), and their absence in phrase-based models is quite evident when looking at MT system output.
P05-1058	J93-2003	o	1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al. , 1993).
D07-1115	W06-1642	o	(Kanayama and Nasukawa, 2006) reported that it was appropriate in 72.2% of cases.
N07-1061	P02-1040	o	To set the weights, m, we carried out minimum error rate training (Och, 2003) using BLEU (Papineni et al. , 2002) as the objective function.
W04-2328	N03-5008	p	5.2 Results We use a Maximum Entropy (ME) classi er (Manning and Klein, 2003) which allows an e cient combination of many overlapping features.
W07-0738	W05-0904	o	CP-STM(i)-l This metric corresponds to the STM metric presented by Liu and Gildea (2005).
D07-1028	P06-1130	n	This additional conditioning has the effect of making the choice of generation rules sensitive to the history of the generation process, and, we argue, provides a simpler, more uniform, general, intuitive and natural probabilistic generation model obviating the need for CFG-grammar transforms in the original proposal of (Cahill and van Genabith, 2006).
W06-0139	W95-0107	o	2.1 Word Sequence Classification Similar to English text chunking (Ramshaw and Marcus, 1995; Wu et al. , 2006a), the word sequence classification model aims to classify each word via encoding its context features.
D09-1105	P03-1021	o	We used GIZA++ (Och and Ney, 2003) to align approximately 751,000 sentences from the German-English portion of the Europarl corpus (Koehn, 2005), in both the German-to-English and English-to-German directions.
H05-1024	N03-1017	o	The standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (Och and Ney, 2000; Koehn et al. , 2003)henceforth referred to as RA. Several researchers have proposed algorithms for improving word alignment systems by injecting additional knowledge or combining different alignment models.
E95-1003	J93-1007	p	One of the best efforts to quantify the performance of a term-recognition system (Smadja, 1993) does so only for one processing stage, leaving unassessed the text-to-output performance of the system.
P09-2080	P07-1056	o	The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009).
P06-1110	W96-0213	o	POS tag the text using the tagger of Ratnaparkhi (1996).
P05-3018	J93-2004	n	a time-consuming process (Litman and Pan, 2002; Marcus et al. , 1993; Xia et al. , 2000; Wiebe, 2002).
P04-1084	J97-3002	o	Thus, GCNF is a more restrictive normal form than those used by Wu (1997) and Melamed (2003).
N09-1025	N04-1035	o	From this data, we use the the GHKM minimal-rule extraction algorithm of (Galley et al., 2004) to yield rules like: NP-C(x0:NPB PP(IN(of x1:NPB))$x1 de x0 Though this rule can be used in either direction, here we use it right-to-left (Chinese to English).
P05-1020	W02-1001	o	Following previous work on using global features of candidate structures to learn a ranking model (Collins, 2002), the global (i.e. , partition-based) features we consider here are simple functions of the local features that capture the relationship between NP pairs.
P98-1082	P90-1034	o	Works on word similarity and word sense disambiguation are generally based on statistical methods designed for large or even very large corpora (Hindle, 1990; Agirre and Rigau, 1996).
P04-1087	P02-1047	o	4.1.1 Lexical co-occurrences Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks (Lapata and Lascarides, 2004; Marcu and Echihabi, 2002).
P06-1082	J93-2003	o	1 Introduction Several approaches including statistical techniques (Gale and Church, 1991; Brown et al. , 1993), lexical techniques (Huang and Choi, 2000; Tiedemann, 2003) and hybrid techniques (Ahrenberg et al. , 2000), have been pursued to design schemes for word alignment which aims at establishing links between words of a source language and a target language in a parallel corpus.
N03-1017	J97-3002	o	Another motivation to evaluate the performance of a phrase translation model that contains only syntactic phrases comes from recent efforts to built syntactic translation models [Yamada and Knight, 2001; Wu, 1997].
C08-1042	D07-1031	o	In cases where the number of gold tags is different than the number of induced tags, some must necessarily remain unassigned (Johnson, 2007).
W06-1668	P97-1003	o	This kind of smoothing has also been used in the generative parser of (Collins, 1997) and has been shown to have a relatively good performance for language modeling (Goodman, 2001).
W07-0737	W05-0909	o	al. 2006), we are interested in applying alternative metrics such a Meteor (Banerjee and Lavie 2005).
P06-1043	N06-1020	o	Thus, the WSJ+NANC model has better oracle rates than the WSJ model (McClosky et al. , 2006) for both the WSJ and BROWN domains.
W07-2218	P07-1080	p	They are latent variable models which are not tractable to compute exactly, but two approximations exist which have been shown to be effective for constituent parsing (Titov and Henderson, 2007).
N09-1034	P08-1045	o	Automatic NE transliteration is an important component in many cross-language applications, such as Cross-Lingual Information Retrieval (CLIR) and Machine Translation(MT) (Hermjakob et al., 2008; Klementiev and Roth, 2006a; Meng et al., 2001; Knight and Graehl, 1998).
J00-2004	J93-1003	o	(1993b), this model is symmetric, because both word bags are generated together from a joint probability distribution.
W99-0621	W95-0107	o	This is similar to results in the literature (Ramshaw and Marcus, 1995).
E99-1023	W95-0107	o	Ramshaw and Marcus used transformationbased learning (TBL) for developing two chunkers (Ramshaw and Marcus, 1995).
W09-0440	W05-0904	o	Three kinds of metrics have been defined: 1 2 candc DR-STM-l (Semantic Tree Matching) These metrics are similar to the Syntactic Tree Matching metric defined by Liu and Gildea (2005), in this case applied to DRSs instead of constituency trees.
P06-2124	P02-1040	o	For word alignment accuracy, F-measure is reported, i.e., the harmonic mean of precision and recall against a gold-standard reference set; for translation quality, Bleu (Papineni et al. , 2002) and its variation of NIST scores are reported.
P07-1106	W02-1001	o	Liang (2005) uses the discriminative perceptron algorithm (Collins, 2002) to score whole character tag sequences, finding the best candidate by the global score.
W07-1429	N03-1003	o	As our work is based on the first paradigm, we will focus on the works proposed by (Barzilay & Lee, 2003) and (Le Nguyen & Ho, 2004).
P08-1001	D07-1074	o	Cucerzan (2007), by contrast to the above, used Wikipedia primarily for Named Entity Disambiguation, following the path of Bunescu and Paca (2006).
D08-1033	P07-1107	o	CRP-based samplers have served the communitywellinrelatedlanguagetasks,suchaswordsegmentation and coreference resolution (Goldwater et al., 2006; Haghighi and Klein, 2007).
W08-2008	W04-1013	o	Finally, in order to formally evaluate the method and the different heuristics, a large-scale evaluation on the BioMed Corpus is under way, based on computing the ROUGE measures (Lin, 2004).
P04-1058	P97-1003	p	They are central to many parsing models (Charniak, 1997; Collins, 1997, 2000; Eisner, 1996), and despite their simplicity n-gram models have been very successful.
D07-1128	J93-2004	o	We use a hand-written competence grammar, combined with performance-driven disambiguation obtained from the Penn Treebank (Marcus et al. , 1993).
W08-2101	J93-2004	o	2 The Data Our experiments on joint syntactic and semantic parsing use data that is produced automatically by merging the Penn Treebank (PTB) with PropBank (PRBK) (Marcus et al., 1993; Palmer et al., 2005), as shown in Figure 1.
D08-1036	D07-1031	o	We ran each estimator with the eight different combinations of values for the hyperparameters  and prime listed below, which include the optimal values for the hyperparameters found by Johnson (2007), and report results for the best combination for each estimator below 1.
P08-1058	P07-1065	p	Following (Talbot and Osborne, 2007a) we can avoid unnecessary false positives by not querying for the longer n-gram in such cases.
D07-1102	P07-1050	o	3 Results and Analysis Hall (2007) shows that the oracle parsing accuracy of a k-best edge-factored MST parser is considerably higher than the one-best score of the same parser, even when k is small.
W05-0906	P02-1040	o	This idea of employing n-gram co-occurrence statistics to score the output of a computer system against one or more desired reference outputs has its roots in the BLEU metric for machine translation (Papineni et al. , 2002) and the ROUGE (Lin and Hovy, 2003) metric for summarization.
W97-1005	J96-1002	o	The approach made use of a maximum entropy model (Berger et al. , 1996) formulated from frequency information for various combinations of the observed features.
N07-2031	P04-1041	o	The feasibility of such post-parse deepening (for a statistical parser) is demonstrated by Cahill et al (2004).
C02-2025	P97-1003	o	Most probabilistic parsing research  including, for example, work by by Collins (1997), and Charniak (1997)  is based on branching process models (Harris, 1963).
P96-1006	A92-1018	o	Making such an assumption is reasonable since POS taggers that can achieve accuracy of 96% are readily available to assign POS to unrestricted English sentences (Brill, 1992; Cutting et al. , 1992).
W07-2090	W02-1001	o	The tagger is a Hidden Markov Model trained with the perceptron algorithm introduced in (Collins, 2002), which applies Viterbi decoding and is regularized using averaging.
P06-2079	P04-1035	p	Note that our result on Dataset A is as strong as that obtained by Pang and Lee (2004) via their subjectivity summarization algorithm, which retains only the subjective portions of a document.
P06-2109	W04-1013	o	ROUGE (Lin, 2004) is a set of recall-based criteria that is mainly used for evaluating summarization tasks.
D09-1057	J96-1002	p	2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as log-linear and exponential learning models, provideageneralpurposemachinelearningtechnique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification.
P03-1055	P97-1003	o	controlled NP-traces (NPNP), we follow the standard technique of marking nodes dominating the empty element up to but not including the parent of the antecedent as defective (missing an argument) with a gap feature (Gazdar et al. , 1985; Collins, 1997).1 Furthermore, to make antecedent co-indexation possible with many types of EEs, we generalize Collins approach by enriching the annotation of non-terminals with the type of the EE in question (eg.
W09-1802	W00-0405	o	both relevant and non-redundant (Goldstein et al., 2000; Nenkova and Vanderwende, 2005), some recent work focuses on improved search (McDonald, 2007; Yih et al., 2007).
N06-2034	P02-1047	o	(Marcu and Echihabi 2002) proposed a method to identify discourse relations between text segments using Nave Bayes classifiers trained on a huge corpus.
N09-1001	P04-1035	o	W(S,T) = summationdisplay uS,vT w(u,v) Globally optimal minimum cuts can be found in polynomial time and near-linear running time in practice, using the maximum flow algorithm (Pang and Lee, 2004; Cormen et al., 2002).
N09-1055	P02-1053	o	The research of opinion mining began in 1997, the early research results mainly focused on the polarity of opinion words (Hatzivassiloglou et al., 1997) and treated the text-level opinion mining as a classification of either positive or negative on the number of positive or negative opinion words in one text (Turney et al., 2003; Pang et al., 2002; Zagibalov et al., 2008;).
W08-0302	P02-1040	o	The weights 1,,M are typically learned to directly minimize a standard evaluation criterion on development data (e.g., the BLEU score; Papineni et al., (2002)) using numerical search (Och, 2003).
J95-2004	A92-1018	o	Unlike stochastic approaches to part-of-speech tagging (Church 1988; Kupiec 1992; Cutting et al. 1992; Merialdo 1990; DeRose 1988; Weischedel et al. 1993), up to now the knowledge found in finite-state taggers has been handcrafted and was not automatically acquired.
W07-2217	J93-2004	o	5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank (Marcus et al. , 1993); i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation.
W05-1507	P97-1003	o	Bilexical CFG is at the heart of most modern statistical parsers (Collins, 1997; Charniak, 1997), because the statistics associated with word-specific rules are more informative for disambiguation purposes.
P07-1094	J92-4003	o	Distributional clustering and dimensionality reduction techniques are typically applied when linguistically meaningful classes are desired (Schutze, 1995; Clark, 2000; Finch et al. , 1995); probabilistic models have been used to find classes that can improve smoothing and reduce perplexity (Brown et al. , 1992; Saul and Pereira, 1997).
J05-1003	W02-1001	p	Results from Collins, Schapire and Singer (2002) show that under these definitions the following guarantee holds: LogLossUpda,k, BestWtk, a C20 BestLossk, a So it can be seen that the update from a to Upda, k, BestWtk, a is guaranteed to decrease LogLoss by at least  W  k q C0  W C0 k qC16C17 2 . From these results, the algorithms in Figures 3 and 4 could be altered to take the revised definitions of W  k and W C0 k into account.
W09-2415	P08-1052	o	They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set.
W96-0203	J93-2004	o	In general the training set is the parsed Wall Street Journal (Marcus et al, 1993), with few exceptions, and the size of the training samples is around 10-20,000 test cases.
P09-1035	W05-0904	o	But there is also extensive research focused on including linguistic knowledge in metrics (Owczarzak et al., 2006; Reeder et al., 2001; Liu and Gildea, 2005; Amigo et al., 2006; Mehay and Brew, 2007; Gimenez and M`arquez, 2007; Owczarzak et al., 2007; Popovic and Ney, 2007; Gimenez and M`arquez, 2008b) among others.
D09-1114	C08-1005	o	Although various approaches to SMT system combination have been explored, including enhanced combination model structure (Rosti et al., 2007), better word alignment between translations (Ayan et al., 2008; He et al., 2008) and improved confusion network construction (Rosti et al., 2008), most previous work simply used the ensemble of SMT systems based on different models and paradigms at hand and did not tackle the issue of how to obtain the ensemble in a principled way.
D07-1028	P06-1130	o	In the LFG-based generation algorithm presented by Cahill and van Genabith (2006) complex named entities (i.e. those consisting of more than one word token) and other multi-word units can be fragmented in the surface realization.
C04-1188	P03-1001	p	In our future work we plan to investigate the effect of more sophisticated and, probably, more accurate filtering methods (Fleischman et al. , 2003) on the QA results.
E09-1048	D07-1047	n	Our approach not only outperformed a notoriously difficult baseline but also achieved similar performance to the approach of (Svore et al., 2007), without requiring their third-party data resources.
P99-1032	J93-2004	o	Two disjoint corpora are used in steps 2 and 5, both consisting of complete articles taken from the Wall Street Journal Treebank Corpus (Marcus et al. , 1993).
H05-1083	J93-2004	o	As for parser, we train three off-shelf maximum-entropy parsers (Ratnaparkhi, 1999) using the Arabic, Chinese and English Penn treebank (Maamouri and Bies, 2004; Xia et al. , 2000; Marcus et al. , 1993).
C04-1030	P02-1040	o	This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al. , 2002).
W04-2602	A92-1018	p	It has been known for some years that good performance can be realized with partial tagging and a hidden Markov model (Cutting et al. , 1992).
W07-1202	P04-1015	o	Parsing research has also begun to adopt discriminative methods from the Machine Learning literature, such as the perceptron (Freund and Schapire, 1999; Collins and Roark, 2004) and the largemargin methods underlying Support Vector Machines (Taskar et al. , 2004; McDonald, 2006).
P06-1062	J93-2003	o	is combined with [ ]E jiT,1+ to be aligned with [ ] F nmT,, then [ ]( ) [ ]( )ATTCNTATTr E K E i FEF jinmjinm,.Pr,P,1],[,],[ ],1[ += where K is the degree of .EiN Finally, the node translation probability is modeled as ( ) ( ) ( )tNtNlNlNNN EiFlEiFlEjFl PrPrPr  . And the text translation probability ( )EF ttPr is model using IBM model I (Brown et al 1993).
P04-1066	J93-2003	p	1 Introduction IBM Model 1 (Brown et al. , 1993a) is a wordalignment model that is widely used in working with parallel bilingual corpora.
P06-2061	J93-2003	o	We rescore the ASR N-best lists with the standard HMM (Vogel et al. , 1996) and IBM (Brown et al. , 1993) MT models.
D08-1021	N04-1035	o	Other recent work has incorporated constituent and dependency subtrees into the translation rules used by phrase-based systems (Galley et al., 2004; Quirk et al., 2005).
W03-0301	J93-2003	o	Four teams had approaches that relied (to varying degrees) on an IBM model of statistical machine translation (Brown et al. , 1993).
E09-1090	P07-1104	o	The L1 or L2 norm is commonly used in statistical natural language processing (Gao et al., 2007).
W07-2007	J96-2004	o	Annotation was highly reliable with a kappa (Carletta, 1996) of 3 factbook/index.html 4Given that the task is not about standard Named Entity Recognition, we assume that the general semantic class of the name is already known.
I08-6006	J93-2003	o	Most current transliteration systems use a generative model for transliteration such as freely available GIZA++1 (Och and Ney , 2000),an implementation of the IBM alignment models (Brown et al., 1993).
I08-2097	D07-1013	o	dependency lengths: Long-distance dependencies exhibit bad performance (McDonald and Nivre, 2007).
W99-0908	P95-1026	o	The preliminary labeling by keyword matching used in this paper is similar to the seed collocations used by Yarowsky (1995).
W09-1114	W06-1673	o	Our use of Gibbs sampling follows from its increasing use in Bayesian inference problems in NLP (Finkel et al., 2006; Johnson et al., 2007b).
D09-1005	P03-1021	o	7.2 Minimum-Risk Training Adjusting  or  changes the distribution p. Minimum error rate training (MERT) (Och, 2003) tries to tune  to minimize the BLEU loss of a decoder that chooses the most probable output according to p.
P08-2065	W02-1011	o	Experiment Implementation: We apply SVM algorithm to construct our classifiers which has been shown to perform better than many other classification algorithms (Pang et al., 2002).
D09-1023	N03-1017	o	These estimates are usually heuristic and inconsistent (Koehn et al., 2003).
I05-2041	J93-2004	p	This kind of corpus has served as an extremely valuable resource for computational linguistics applications such as machine translation and question answering (Lee et al. , 1997; Choi, 2001), and has also proved useful in theoretical linguistics research (Marcus et al. , 1993).
N07-2053	N03-1017	o	(2006), modified from (Koehn et al. , 2003), which is an average of pairwise word translation probabilities.
E95-1037	J90-1003	o	, 1989), e.g, lexicography (Church and Hanks, 1990), information retrieval (Salton, 1986a), text input (Yamashina and Obashi, 1988), etc. This paper will touch on its feasibility in topic identification.
P07-1001	P02-1040	o	We measure translation performance by the BLEU score (Papineni et al. , 2002) and Translation Error Rate (TER) (Snover et al. , 2006) with one reference for each hypothesis.
D09-1106	P02-1040	o	We evaluated the translation quality using case-insensitive BLEU metric (Papineni et al., 2002).
I08-2097	D07-1112	o	Dredze et al. also indicated that unlabeled dependency parsing is not robust to domain adaptation (Dredze et al., 2007).
D08-1084	J93-2003	o	The MT community has developed not only an extensive literature on alignment (Brown et al., 1993; Vogel et al., 1996; Marcu and Wong, 2002; DeNero et al., 2006), but also standard, proven alignment tools such as GIZA++ (Och and Ney, 2003).
P06-1031	W91-0208	o	or cooking, which agrees with the knowledge presented in previous work (Ostler and Atkins, 1991).
P03-1008	J96-2004	o	The annotation can be considered reliable (Krippendorff, 1980) with 95% agreement and a kappa (Carletta, 1996) of.88.
P04-3025	W02-1011	n	Although such approaches have been employed effectively (Pang et al. , 2002), there appears to remain considerable room for improvement.
P08-1079	P06-1101	o	2.1 Relationship Types There is a large body of related work that deals with discovery of basic relationship types represented in useful resources such as WordNet, including hypernymy (Hearst, 1992; Pantel et al., 2004; Snow et al., 2006), synonymy (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) and meronymy (Berland and Charniak, 1999; Girju et al., 2006).
L08-1063	W04-1013	o	"Oxford, UK: Oxford University Press.</rawString> </citation> <citation valid=""true""> <authors> <author>L A Black</author> <author>C McMeel</author> <author>M McTear</author> <author>N Black</author> <author>R Harper</author> <author>M Lemon</author> </authors> <title>Implementing autonomy in a diabetes management system</title> <date>2005</date> <journal>J Telemed Telecare</journal> <volume>11</volume> <contexts> <context>-care applications, Examples include scheduling appointments over the phone (Zajicek et al. 2004, Wolters et al., submitted), interactive reminder systems (Pollack, 2005), symptom management systems (Black et al. 2005) or environmental control systems (Clarke et al. 2005)."
W06-1606	N03-1017	p	1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy.
W04-0813	P95-1026	o	The Decision List (DL) algorithm is described in (Yarowsky, 1995b).
W06-1670	W02-1001	o	In this paper we apply perceptron trained HMMs originally proposed in (Collins, 2002).
P04-3026	P95-1026	o	Starting from the list of 12 ambiguous words provided by Yarowsky (1995) which is shown in table 2, we created a concordance for each word, with the lines in the concordances each relating to a context window of 20 words.
D08-1078	P02-1040	o	6.1 Evaluation of Translation Performance We use the BLEU score (Papineni et al., 2002) to evaluate our systems.
W02-0806	J96-2004	o	A detailed discussion on the use of kappa in natural language processing is presented in (Carletta, 1996).
W06-1639	P02-1053	o	In particular, since we treat each individual speech within a debate as a single document, we are considering a version of document-level sentiment-polarity classification, namely, automatically distinguishing between positive and negative documents (Das and Chen, 2001; Pang et al. , 2002; Turney, 2002; Dave et al. , 2003).
P04-3019	J93-1003	p	Moreover, log likelihood ratios are regarded as a more effective method to identify collocations especially when the occurrence count is very low (Dunning, 1993).
W05-0835	J93-2003	o	This concept of alignment has been also used for tasks like authomatic vocabulary derivation and corpus alignment (Dagan et al. , 1993).
J02-2003	J93-1003	o	Dunning (1993) argues for the use of G 2 rather than X 2, based on the claim that the sampling distribution of G 2 approaches the true chi-square distribution quicker than the sampling distribution of X 2 . However, Agresti (1996, page 34) makes the opposite claim: The sampling distributions of X 2 and G 2 get closer to chi-squared as the sample size n increasesThe convergence is quicker for X 2 than G 2 . In addition, Pedersen (2001) questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read (1984), who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic.
D09-1061	P02-1053	p	Turneys (2002) work is perhaps one of the most notable examples of unsupervised polarity classification.
P97-1007	J90-1003	o	Thus, given a hyponym definition (O) and a set of candidate hypernym definitions, this method selects the candidate hypernym definition (E) which returns the maximum score given by formula (1): SC(O, E) : E cw(wi, wj) (I) 'wIEOAwj6E The cooccurrence weight (cw) between two words can be given by Cooccurrence Frequency, Mutual Information (Church and Hanks, 1990) or Association Ratio (Resnik, 1992).
P07-1108	P02-1040	p	The translation quality was evaluated using a well-established automatic measure: BLEU score (Papineni et al. , 2002).
D09-1108	N04-1035	o	The tree-to-string model (Galley et al. 2004; Liu et al. 2006) views the translation as a structure mapping process, which first breaks the source syntax tree into many tree fragments and then maps each tree fragment into its corresponding target translation using translation rules, finally combines these target translations into a complete sentence.
P07-1002	P06-1123	o	Figure 1(b) shows several orders of the sentence which violate this constraint.1 Previous studies have shown that if both the source and target dependency trees represent linguistic constituency, the alignment between subtrees in the two languages is very complex (Wellington et al. , 2006).
P07-1055	P06-1096	o	Work on learning with hidden variables can be used for both CRFs (Quattoni et al. , 2004) and for inference based learning algorithms like those used in this work (Liang et al. , 2006).
P08-1007	W05-0909	o	2.4 METEOR Given a pair of strings to compare (a system translation and a reference translation), METEOR (Banerjee and Lavie, 2005) first creates a word alignment between the two strings.
C08-1141	P02-1040	p	The state-of-the-art methods for automatic MT evaluation are using an n-gram based metric represented by BLEU (Papineni et al., 2002) and its variants.
C00-1009	J93-2004	o	The part of the 1Release 2 of this data set can be obtained t'rmn the Linguistic Data Consortium with Catalogue number LDC94T4B ( 2There are 48 labels defined in (Marcus et al. , 1993), however, three of ttmm do not appear in the corpus.
P93-1012	P88-1012	o	Volume 17, Number 1 March 1991 References Lakoff, George and Johnson, Mark Metaphors We Live 8y University of Chicago Press 1980 MADCOW Committee (Hirschman, Lynette et al) Multi-Site Data Collection for a Spoken Language Corpus in Proceedings Speech and Natural Language Workshop February 1992 Grice, H. P. Logic and Conversation in P. Cole and J. L. Morgan, Speech Acts, New York: Academic Press, 1975 Pustejovsky, James The Generative Lexicon Computational Linguistics Volume 17, Number 4 December 1991 Hobbs, Jerry R. and Stickel, Mark Interpretation as Abduction in Proceedings of the 26th ACL June 1988 Bobrow, R. , Ingria, R. and Stallard, D. The Mapping Unit Approach to Subcategorization in Proceedings Speech and Natural Language Workshop February 1991 Hobbs, Jerry R. , and Martin, Paul Local Pragmatics in Proceedings, 10th International Joint Conference on Artificial Intelligence (IJCAI-87).
N03-3006	J93-2004	o	The parser has been trained, developed and tested on a large collection of syntactically analyzed sentences, the Penn Treebank (Marcus et al. , 1993).
W00-1306	J93-2004	o	This paper presents an empirical study measuring the effectiveness of our evaluation functions at selecting training sentences from the Wall Street Journal (WSJ) corpus (Marcuset al. , 1993) for inducing grammars.
D08-1059	D07-1013	o	However, they make different types of errors, which can be seen as a reflection of their theoretical differences (McDonald and Nivre, 2007).
D08-1091	H05-1064	o	Discriminative parsing has been investigated before, such as in Johnson (2001), Clark and Curran (2004), Henderson (2004), Koo and Collins (2005), Turian et al.
D08-1012	J97-3002	o	3 Inversion Transduction Grammars While our approach applies in principle to a variety of machine translation systems (phrase-based or syntactic), we will use the inversion transduction grammar (ITG) approach of Wu (1997) to facilitate comparison with previous work (Zens and Ney, 2003;ZhangandGildea,2008)aswellastofocuson language model complexity.
W08-0409	J93-1003	o	Generative word alignment models, initially developed at IBM (Brown et al., 1993), and then augmented by an HMM-based model (Vogel et al., 1996), have provided powerful modeling capability for word alignment.
N07-2010	J93-2003	o	Similar to work in image retrieval (Barnard et al. , 2003), we cast the problem in terms of Machine Translation: given a paired corpus of words and a set of video event representations to which they refer, we make the IBM Model 1 assumption and use the expectation-maximization method to estimate the parameters (Brown et al. , 1993):  =+ = m j ajm jvideowordpl Cvideowordp 1 )|()1()|( (1) This paired corpus is created from a corpus of raw video by first abstracting each video into the feature streams described above.
P06-2005	P02-1040	o	We use IBMs BLEU score (Papineni et al. , 2002) to measure the performance of SMS text normalization.
D07-1096	P97-1003	o	Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English.
P09-1031	C98-2122	o	Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used cooccurrence statistics in local context to discover sibling relations.
W06-1636	J93-2004	o	1 Introduction and Previous Research It is by now commonplace knowledge that accurate syntactic parsing is not possible given only a context-free grammar with standard Penn Treebank (Marcus et al. , 1993) labels (e.g. , S, NP, etc).
N09-1066	W04-1013	o	Our aim is not only to determine the utility of citation texts for survey creation, but also to examine the quality distinctions between this form of input and others such as abstracts and full textscomparing the results to human-generated surveys using both automatic and nugget-based pyramid evaluation (Lin and Demner-Fushman, 2006; Nenkova and Passonneau, 2004; Lin, 2004).
C04-1040	J93-2004	o	Dependency Analyzer PP-Attachment Resolver Root-Node Finder Base NP Chunker (POS Tagger) = SVM, = Preference Learning Figure 2: Module layers in the system That is, we use Penn Treebanks Wall Street Journal data (Marcus et al. , 1993).
P06-1071	J96-1002	o	2.1 Conditional Maximum Entropy Model The goal of CME is to find the most uniform conditional distribution of y given observation x, ( )xyp, subject to constraints specified by a set of features ()yxf i,, where features typically take the value of either 0 or 1 (Berger et al. , 1996).
P03-1019	J97-3002	o	For this purpose, we adopt the view of the ITG constraints as a bilingual grammar as, e.g., in (Wu, 1997).
W02-2018	J96-1002	o	A conditional maximum entropy model q(xjw) for p has the parametric form (Berger et al. , 1996; Chi, 1998; Johnson et al. , 1999): q(xjw) = exp T f (x) y2Y(w) exp(T f (y)) (1) where  is a d-dimensional parameter vector and T f (x) is the inner product of the parameter vector and a feature vector.
I08-1013	J93-1003	o	5 jacabit/ a4a6a5 which gathers the set of co-occurrence units a7 associated with the number of times that a7 and a2 occur together a8a6a9a10a9 a5 a11 . In order to identify speci c words in the lexical context and to reduce word-frequency effects, we normalize context vectors using an association score such as Mutual Information (Fano, 1961) or Log-likelihood (Dunning, 1993).
N06-2025	J93-2004	o	4.2 Experiments on SRL dataset We used two different corpora: PropBank (www.cis.upenn.edu/ace) along with Penn Treebank 2 (Marcus et al. , 1993) and FrameNet.
P98-2216	J93-1007	o	Other classes, such as the ones below can be extracted using lexico-statistical tools, such as in (Smadja, 1993), and then checked by a human.
C96-1009	J93-1007	o	From the extracted n-grams, those with a flequc'ncy of 3 or more were kept (other approaches get rid of n-grams of such low frequencies (Smadja, 1993)).
D07-1126	W02-1001	o	It is easy to see that the main difference between the PA algorithms and the Perceptron algorithm (PC) (Collins, 2002) as well as the MIRA algorithm (McDonald et al. , 2005a) is in line 9.
P09-1059	W02-1001	p	In addition, the averaged parameters technology (Collins, 2002) is used to alleviate overfitting and achieve stable performance.
D09-1024	C08-1139	o	Word alignment is also a required first step in other algorithms such as for learning sub-sentential phrase pairs (Lavie et al., 2008) or the generation of parallel treebanks (Zhechev and Way, 2002).
D08-1004	N06-1041	o	Haghighi and Klein (2006) do the reverse: for each class label y, they ask the annotators to propose a few prototypical featuresf such thatp(y|f) is as high as possible.
P09-1011	J93-2003	o	This model is similar in spirit to IBM model 1 (Brown et al., 1993).
E99-1015	J96-2004	o	Kappa is a better measurement of agreement than raw percentage agreement (Carletta, 1996) because it factors out the level of agreement which would be reached by random annotators using the same distribution of categories as the real coders.
W96-0203	J93-2004	o	The class based disambiguation operator is the Mutual Conditioned Plausibility (MCPI) (Basili et al. ,1993a).
C04-1040	W96-0213	o	According to the document, it is the output of Ratnaparkhis tagger (Ratnaparkhi, 1996).
D09-1039	P03-1021	o	There has been some previous work on accuracy-driven training techniques for SMT, such as MERT (Och, 2003) and the Simplex Armijo Downhill method (Zhao and Chen, 2009), which tune the parameters in a linear combination of various phrase scores according to a held-out tuning set.
C04-1124	W96-0213	o	 POS tagger: The maximum entropy POS tagger developed by Ratnaparkhi (Ratnaparkhi, 1996) and the rule-based POS tagger developed by Brill (Brill, 1994) are trained with 1200 abstracts extracted from the GENIA corpus, which achieve accuracies of 97.97% and 98.06% respectively, when testing on the rest 800 abstract of the GENIA corpus.
W08-0314	N03-1017	p	3 System Overview 3.1 Translation model The system developed for this years shared task is a state-of-the-art, two-pass phrase-based statistical machine translation system based on a log-linear translation model (Koehn et al, 2003).
N09-2054	P05-1010	o	Rather than explicit annotation, we could use latent annotations to split the POS tags, similarly to the introduction of latent annotations to PCFG grammars (Matsuzaki et al., 2005; Petrov et al., 2006).
P93-1022	J90-1003	o	Statistical data about these various cooccurrence relations is employed for a variety of applications, such as speech recognition (Jelinek, 1990), language generation (Smadja and McKeown, 1990), lexicography (Church and Hanks, 1990), machine translation (Brown et al. , ; Sadler, 1989), information retrieval (Maarek and Smadja, 1989) and various disambiguation tasks (Dagan et al. , 1991; Hindle and Rooth, 1991; Grishman et al. , 1986; Dagan and Itai, 1990).
C00-2118	P97-1003	o	The last two counts (CAUS and ANIM) were performed on a 29-million word parsed corpus (\gall Street Journal 1988, provided by Michael Collins (Collins, 1997)).
W08-2119	N03-1017	o	We use the same features as (Koehn et al., 2003).
W09-1606	P04-1035	o	Pang & Lee (2004) propose the use of language models for sentiment analysis task and subjectivity extraction.
C08-1017	J92-4003	o	(1992) describe one application of MI to identify word collocations; Kashioka et al.
W94-0106	J92-4003	o	It has been used for diverse problems such as machine translation and sense disambiguation \[Gale et al. , 1992, Schiltze, 1992\].
C04-1072	P03-1021	o	 A natural fit to the existing statistical machine translation framework  A metric that ranks a good translation high in an nbest list could be easily integrated in a minimal error rate statistical machine translation training framework (Och 2003).
P04-1084	J97-3002	o	Inversion Transduction Grammar (ITG) (Wu, 1997) and Syntax-Directed Translation Schema (SDTS) (Aho and Ullman, 1969) lack both of these properties.
N09-3013	P02-1053	o	In general, previous work in opinion mining includes document level sentiment classification using supervised (Chaovalit and Zhou, 2005) and unsupervised methods (Turney, 2002), machine learning techniques and sentiment classification considering rating scales (Pang, Lee and Vaithyanathan, 2002), and scoring of features (Dave, Lawrence and Pennock, 2003).
W03-2806	P85-1008	o	The MLFs use reification to achieve flat expressions, very much in the line of Davidson (1967), Hobbs (1985), and Copestake et al.
W02-1405	J93-2003	o	Among them, (Brown et al. , 1993a) have proposed a way to exploit bilingual dictionnaries at training time.
J05-3003	P97-1003	o	The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman (1994) and Collins (1997).
N09-1004	N07-1025	o	Generally, WSD methods use the context of a word for its sense disambiguation, and the context information can come from either annotated/unannotated text or other knowledge resources, such as WordNet (Fellbaum, 1998), SemCor (SemCor, 2008), Open Mind Word Expert (Chklovski and Mihalcea, 2002), eXtended WordNet (Moldovan and Rus, 2001), Wikipedia (Mihalcea, 2007), parallel corpora (Ng, Wang, and Chan, 2003).
D09-1021	P08-1066	o	Other factors that distinguish us from previous work are the use of all phrases proposed by a phrase-based system, and the use of a dependency language model that also incorporates constituent information (although see (Charniak et al., 2003; Shen et al., 2008) for related approaches).
W96-0111	J93-2004	o	The latter approach has become increasingly popular (e.g. Schabes et al. , 1993; Weischedel et al. , 1993; Briscoe, 1994; Magerman, 1995; Collins, 1996).
A00-2030	J93-2004	o	Word features are introduced primarily to help with unknown words, as in (Weischedel et al. 1993).
P09-1070	P06-1101	o	6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly.
D08-1033	P02-1040	o	scored with lowercased, tokenized NIST BLEU, and exact match METEOR (Papineni et al., 2002; Lavie and Agarwal, 2007).
W07-1527	P06-1101	p	Currently, the best-performing English NP interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (Rosario and Hearst, 2001), (Rosario et al. , 2002), (Moldovan et al. , 2004), (Pantel and Pennacchiotti, 2006), (Pennacchiotti and Pantel, 2006), (Kim and Baldwin, 2006), (Snow et al. , 2006), (Girju et al. , 2005; Girju et al. , 2006), or use statistical models on large collections of unlabeled data (Berland and Charniak, 1999), (Lapata and Keller, 2004), (Nakov and Hearst, 2005), (Turney, 2006).
P97-1007	P95-1026	o	Some of them have been fully tested in real size texts (e.g. statistical methods (Yarowsky, 1992), (Yarowsky, 1994), (Miller and Teibel, 1991), knowledge based methods (Sussna, 1993), (Agirre and Rigau, 1996), or mixed methods (Richardson et al. , 1994), (Resnik, 1995)).
P97-1033	J92-4003	o	(Black et al. , 1992; Materman, 1995)), we treat the word identities as a further refinement of the POS tags; thus we build a word classification tree for each POS tag.
P06-1123	N03-1017	o	is relevant to finite-state phrase-based models that use no parse trees (Koehn et al. , 2003), tree-tostring models that rely on one parse tree (Yamada and Knight, 2001), and tree-to-tree models that rely on two parse trees (Groves et al. , 2004, e.g.).
I08-2099	J93-2004	p	Some notable efforts in this direction for other languages have been the Penn Tree Bank (Marcus et al., 1993) for English and the Prague Dependency Bank (Hajicova, 1998) for Czech.
W04-2602	J92-4003	o	Clark (2000) reports results on a corpus containing 12 million terms, Schcurrency1utze (1993) on one containing 25 million terms, and Brown, et al, (1992) on one containing 365 million terms.
N07-1030	J96-1002	o	Model parameters are estimated using maximum entropy (Berger et al. , 1996).
W09-0427	D07-1091	o	Unlike with factored models (Koehn and Hoang, 2007) or additional translation lexicons (Schwenk et al., 2008), we do not generate the surface form back from the lemma translation, which means that tense, gender and number information are 151 news-dev2009a representation OOV % METEOR BLEU NIST baseline surface form only 2.24 49.05 20.45 6.135 decoding lemma backoff 2.13 49.12 20.44 6.143 word alignment lemma+POS for all 2.24 48.87 20.36 6.145 lemma+POS for adj 2.25 48.94 20.46 6.131 lemma+POS for verbs 2.21 49.05 20.47 6.137 decoding + alignment backoff + all 2.10 48.97 20.36 6.147 backoff + adj 2.12 49.05 20.48 6.140 backoff + verbs 2.08 49.15 20.50 6.148 news-dev2009b representation OOV % METEOR BLEU NIST baseline surface form only 2.52 49.60 21.10 6.211 decoding lemma backoff 2.43 49.66 21.02 6.210 word alignment lemma+POS for all 2.53 49.56 21.03 6.199 lemma+POS for adj 2.52 49.74 21.00 6.213 lemma+POS for verbs 2.47 49.73 21.10 6.217 decoding+alignment backoff + all 2.44 49.59 20.92 6.194 backoff + adj 2.43 49.80 21.03 6.217 backoff + verbs 2.39 49.80 21.03 6.217 Table 2: Evaluation of the decoding backoff strategy, the modified word alignment strategy and their combination Input Meme sil demissionnait, la situation ne changerait pas.
D09-1105	P07-1003	o	The second alternative used BerkeleyAligner (Liang et al., 2006; DeNero and Klein, 2007), which shares information between the two alignment directions to improve alignment quality.
P09-2043	P08-1036	o	Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments (Titov and McDonald, 2008).
P06-2101	P03-1021	o	Despite these difficulties, some work has shown it worthwhile to minimize error directly (Och, 2003; Bahl et al. , 1988).
D07-1033	W02-1001	o	2(Daume III and Marcu, 2005) also presents the method using the averaged perceptron (Collins, 2002a) 3For re-ranking problems, Shen and Joshi (2004) proposed a perceptron algorithm that also uses margins.
W07-0719	P06-1091	o	However, at the short term, the incorporation of these type of features will force us to either build a new decoder or extend an existing one, or to move to a new MT architecture, for instance, in the fashion of the architectures suggested by Tillmann and Zhang (2006) or Liang et al.
I08-2078	W02-1001	p	A pioneer work in online training is the perceptron-like algorithm used in training a hidden Markov model (HMM) (Collins, 2002).
P07-1056	W02-1011	o	After this conversion, we had 1000 positive and 1000 negative examples for each domain, the same balanced composition as the polarity dataset (Pang et al. , 2002).
W06-1006	J93-1007	o	Morphologicaltoolssuch as lemmatizers andPOStaggersarebeingcommonlyusedin extractionsystems;they areemployedbothfordealingwithtext variationandfor validatingthe candidatepairs: combinationsof functionwordsare typicallyruledout (Justesonand Katz, 1995),as are the ungrammaticalcombinationsin the systemsthatmake useofparsers(ChurchandHanks, 1990;Smadja,1993;Basilietal.
P01-1067	J93-2003	o	Let a183a49a48a50 a69 a188 a50 a51a181a51a181a51a212a188 a50a7a51a24a52 a48a54a53 a185a56a55 be a substring of a183 from the word a188 a50 with length a57 . Note this notation is different from (Brown et al. , 1993).
W09-2208	P95-1026	o	Collins et al.(Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowskys method (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998).
